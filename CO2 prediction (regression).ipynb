{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Brief \n",
    "\n",
    "## Deadline: Tuesday, October 29, 2019 at 14:00 hrs\n",
    "\n",
    "## Number of marks available: 20\n",
    "\n",
    "## Scope: Sessions 1 to 5\n",
    "\n",
    "### How and what to submit\n",
    "\n",
    "A. Submit a Jupyter Notebook named COM4509-6509_Assignment_1_UCard_XXXXXXXXX.ipynb where XXXXXXXXX refers to your UCard number.\n",
    "\n",
    "B. Upload the notebook file to MOLE before the deadline above.\n",
    "\n",
    "C. **NO DATA UPLOAD**: Please do not upload the data files used. We have a copy already. \n",
    "\n",
    "\n",
    "### Assessment Criteria \n",
    "\n",
    "* Being able to express an objective function and its gradients in matrix form.\n",
    "\n",
    "* Being able to use numpy and pandas to preprocess a dataset.\n",
    "\n",
    "* Being able to use numpy to build a machine learning pipeline for supervised learning. \n",
    "\n",
    "\n",
    "### Late submissions\n",
    "\n",
    "We follow Department's guidelines about late submissions, i.e., a deduction of 5% of the mark each working day the work is late after the deadline. NO late submission will be marked one week after the deadline because we will release a solution by then. Please read [this link](https://sites.google.com/sheffield.ac.uk/compgtstudenthandbook/menu/assessment/late-submission?pli=1&authuser=1). \n",
    "\n",
    "### Use of unfair means \n",
    "\n",
    "**\"Any form of unfair means is treated as a serious academic offence and action may be taken under the Discipline Regulations.\"** (from the MSc Handbook). Please carefully read [this link](https://sites.google.com/sheffield.ac.uk/compgtstudenthandbook/menu/referencing-unfair-means?pli=1&authuser=1) on what constitutes Unfair Means if not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisation for Linear Regression\n",
    "\n",
    "Regularisation is a technique commonly used in Machine Learning to prevent overfitting. It consists on adding terms to the objective function such that the optimisation procedure avoids solutions that just learn the training data. Popular techniques for regularisation in Supervised Learning include Lasso Regression, Ridge Regression and the Elastic Net. \n",
    "\n",
    "In this Assignment, you will be looking at Ridge Regression and devising equations to optimise the objective function in Ridge Regression using two methods: a closed-form derivation and the update rules for stochastic gradient descent. You will then use those update rules for making predictions on a Air Quaility dataset.\n",
    "\n",
    "## Ridge Regression\n",
    "\n",
    "Let us start with a data set for training $\\mathcal{D} = \\{\\mathbf{y}, \\mathbf{X}\\}$, where the vector $\\mathbf{y}=[y_1, \\cdots, y_n]^{\\top}$ and $\\mathbf{X}$ is the design matrix from Lab 3, this is, \n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{X} = \n",
    "                \\begin{bmatrix}\n",
    "                        1 & x_{1,1} & \\cdots & x_{1, D}\\\\\n",
    "                        1 & x_{2,1} & \\cdots & x_{2, D}\\\\\n",
    "                   \\vdots &  \\vdots\\\\\n",
    "                        1 & x_{n,1} & \\cdots & x_{n, D}\n",
    "                \\end{bmatrix}\n",
    "               = \n",
    "               \\begin{bmatrix}\n",
    "                      \\mathbf{x}_1^{\\top}\\\\\n",
    "                       \\mathbf{x}_2^{\\top}\\\\\n",
    "                          \\vdots\\\\\n",
    "                        \\mathbf{x}_n^{\\top}\n",
    "                \\end{bmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "Our predictive model is going to be a linear model\n",
    "\n",
    "$$ f(\\mathbf{x}_i) = \\mathbf{w}^{\\top}\\mathbf{x}_i,$$\n",
    "\n",
    "where $\\mathbf{w} = [w_0\\; w_1\\; \\cdots \\; w_D]^{\\top}$.\n",
    "\n",
    "The **objetive function** we are going to use has the following form\n",
    "\n",
    "$$ J(\\mathbf{w}, \\alpha) = \\frac{1}{n}\\sum_{i=1}^n (y_i - f(\\mathbf{x}_i))^2 + \\frac{\\alpha}{2}\\sum_{j=0}^D w_j^2,$$\n",
    "\n",
    "where $\\alpha>0$ is known as the *regularisation* parameter.\n",
    "\n",
    "The first term on the right-hand side (rhs) of the expression for $J(\\mathbf{w}, \\alpha)$ is very similar to the least-squares objective function we have seen before, for example in Lab 3. The only difference is on the term $\\frac{1}{n}$ that we use to normalise the objective with respect to the number of observations in the dataset. \n",
    "\n",
    "The first term on the rhs is what we call the \"fitting\" term whereas the second term in the expression is the regularisation term. Given $\\alpha$, the two terms in the expression have different purposes. The first term is looking for a value of $\\mathbf{w}$ that leads the squared-errors to zero. While doing this, $\\mathbf{w}$ can take any value and lead to a solution that it is only good for the training data but perhaps not for the test data. The second term is regularising the behavior of the first term by driving the $\\mathbf{w}$ towards zero. By doing this, it restricts the possible set of values that $\\mathbf{w}$ might take according to the first term. The value that we use for $\\alpha$ will allow a compromise between a value of $\\mathbf{w}$ that exactly fits the data (first term) or a value of $\\mathbf{w}$ that does not grow too much (second term).\n",
    "\n",
    "This type of regularisation has different names: ridge regression, Tikhonov regularisation or $\\ell_2$ norm regularisation. \n",
    "\n",
    "### Question 1: $J(\\mathbf{w}, \\alpha)$ in matrix form (2 marks)\n",
    "\n",
    "Write the expression for $J(\\mathbf{w}, \\alpha)$ in matrix form. Include ALL the steps necessary to reach the expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 Answer\n",
    "\n",
    "$$ J(\\mathbf{w}, \\alpha) = \\frac{1}{n}\\sum_{i=1}^n (y_i - f(\\mathbf{x}_i))^2 + \\frac{\\alpha}{2}\\sum_{j=0}^D w_j^2,$$\n",
    "defining \n",
    "$$\n",
    "\\mathbf{y} = \\begin{bmatrix}y_1\\\\y_2\\\\ \\vdots \\\\ y_n\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and defining\n",
    "$$\n",
    "\\mathbf{f}(\\mathbf{X}; \\mathbf{w}) = \\begin{bmatrix}f(\\mathbf{x}_1; \\mathbf{w})\\\\f(\\mathbf{x}_2; \\mathbf{w})\\\\ \\vdots \\\\ f(\\mathbf{x}_n; \\mathbf{w})\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "ignore the dependence of $\\mathbf{f}$ on $\\mathbf{w}$ and $\\mathbf{X}$ and simply summarise it by a vector of numbers\n",
    "$$\n",
    "\\mathbf{f} = \\begin{bmatrix}f_1\\\\f_2\\\\ \\vdots \\\\ f_n\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "because $\\mathbf{w}$ and $\\mathbf{x}_i$ are two column vectors,$\\mathbf{f}$ is the inner products between $\\mathbf{w} $ and $\\mathbf{x}_i$, they satisfy commutative law, then we have\n",
    "\n",
    "$$ f(\\mathbf{x}_i) = \\mathbf{w}^{\\top}\\mathbf{x}_i =\\mathbf{x}_i^{\\top}\\mathbf{w} $$\n",
    "\n",
    "so vector $\\mathbf{f}$ is a series inner product between $\\mathbf{w}$ and $\\mathbf{x}_i$\n",
    "\n",
    "then rewrite it as \n",
    "$$\n",
    "\\mathbf{f} = \\mathbf{X}\\mathbf{w}.\n",
    "$$\n",
    "That is to say, $\\mathbf{f}$ is a n dimensional vector (which we can intepret as a n×1 dimensional matrix), and $\\mathbf{X}$ is a n×n dimensional matrix and $\\mathbf{w}$ is a n dimensional vector (n×1 dimensional matrix).\n",
    "\n",
    "\n",
    "because\n",
    "$$\n",
    "\\sum_{j=0}^{D} w^2_j = \\mathbf{w}^\\top\\mathbf{w},\n",
    "$$\n",
    "\n",
    "and $\\alpha$ is given,then rewrite the objective function\n",
    "\n",
    "$$ J(\\mathbf{w}, \\alpha) = \\frac{1}{n}(\\mathbf{y} - \\mathbf{X}\\mathbf{w})^\\top(\\mathbf{y} - \\mathbf{X}\\mathbf{w}) + \\frac{\\alpha}{2}\\mathbf{w}^\\top\\mathbf{w}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising the objective function with respect to $\\mathbf{w}$\n",
    "\n",
    "There are two ways we can optimise the objective function with respect to $\\mathbf{w}$. The first one leads to a closed form expression for $\\mathbf{w}$ and the second one using an iterative optimisation procedure that updates the value of $\\mathbf{w}$ at each iteration by using the gradient of the objective function with respect to $\\mathbf{w}$,\n",
    "$$\n",
    "\\mathbf{w}_{\\text{new}} = \\mathbf{w}_{\\text{old}} - \\eta \\frac{d J(\\mathbf{w}, \\alpha)}{d\\mathbf{w}},\n",
    "$$\n",
    "where $\\eta$ is the *learning rate* parameter and $\\frac{d J(\\mathbf{w}, \\alpha)}{d\\mathbf{w}}$ is the gradient of the objective function.\n",
    "\n",
    "### Question 2: Derivative of $J(\\mathbf{w}, \\alpha)$ wrt $\\mathbf{w}$ (2 marks)\n",
    "\n",
    "Find the closed-form expression for $\\mathbf{w}$ by taking the derivative of $J(\\mathbf{w}, \\alpha)$ with respect to \n",
    "$\\mathbf{w}$, equating to zero and solving for $\\mathbf{w}$. Write the expression in matrix form. \n",
    "\n",
    "Also, write down the specific update rule for $\\mathbf{w}_{\\text{new}}$ by using the equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 Answer\n",
    "\n",
    "The objective function in matrix form:\n",
    "$$\n",
    "J(\\mathbf{w}, \\alpha) = \\frac{1}{n}(\\mathbf{y} - \\mathbf{f})^\\top(\\mathbf{y} - \\mathbf{f}) + \\frac{\\alpha}{2}\\mathbf{w}^\\top\\mathbf{w}\n",
    "$$\n",
    "\n",
    "because\n",
    "$$ f(\\mathbf{x}_i) = \\mathbf{w}^{\\top}\\mathbf{x}_i,$$\n",
    "\n",
    "as we mentioned in question 1\n",
    "$$\n",
    "\\mathbf{f} = \\mathbf{X}\\mathbf{w}\n",
    "$$\n",
    "Rewrite the objective function\n",
    "$$\n",
    "J(\\mathbf{w}, \\alpha) = \\frac{1}{n}(\\mathbf{y} - \\mathbf{X}\\mathbf{w})^\\top(\\mathbf{y} - \\mathbf{X}\\mathbf{w}) + \\frac{\\alpha}{2}\\mathbf{w}^\\top\\mathbf{w}\n",
    "$$ \n",
    "\n",
    "so\n",
    "$$\n",
    "\\frac{d J(\\mathbf{w}, \\alpha)}{d \\mathbf{w}} = - \\frac{2}{n}\\mathbf{X}^\\top \\mathbf{y} + \\frac{2}{n}\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w} + \\alpha\\mathbf{w}\n",
    "$$\n",
    "\n",
    "let$\\frac{d J(\\mathbf{w}, \\alpha)}{d \\mathbf{w}}=\\mathbf{0}$\n",
    "$$ \\mathbf{0} = - \\frac{2}{n}\\mathbf{X}^\\top \\mathbf{y} + \\frac{2}{n}\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w} + \\alpha\\mathbf{w}$$\n",
    "where $\\mathbf{0}$ is a vector of zero,then we have\n",
    "$$\n",
    "\\mathbf{w}^* = \\left[\\frac{2}{n}\\mathbf{X}^\\top\\mathbf{X} + \\alpha\\mathbf{I}\\right]^{-1}\\frac{2}{n}\\mathbf{X}^\\top \\mathbf{y}\n",
    "$$\n",
    "where $\\mathbf{I}$ is a identity matrix\n",
    "\n",
    "so\n",
    "$$\n",
    "\\mathbf{w}_{\\text{new}} = \\mathbf{w}_{\\text{old}} + \\eta (\\frac{2}{n}\\mathbf{X}^\\top \\mathbf{y} - \\frac{2}{n}\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w} - \\alpha\\mathbf{w})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ridge regression to predict air quality\n",
    "\n",
    "Our dataset comes from a popular machine learning repository that hosts open source datasets for educational and research purposes, the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). We are going to use ridge regression for predicting air quality. The description of the dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/Air+Quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading  https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip -> .\\AirQualityUCI.zip\n",
      "[===========================   ]   1.328/1.472MB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [==============================]   1.472/1.472MB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n"
     ]
    }
   ],
   "source": [
    "import pods\n",
    "pods.util.download_url('https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip')\n",
    "import zipfile\n",
    "zip = zipfile.ZipFile('./AirQualityUCI.zip', 'r')\n",
    "for name in zip.namelist():\n",
    "    zip.extract(name, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .csv version of the file has some typing issues, so we use the excel version\n",
    "import pandas as pd \n",
    "air_quality = pd.read_excel('./AirQualityUCI.xlsx', usecols=range(2,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some of the rows in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable corresponds to the CO(GT) variable of the first column. The following columns correspond to the variables in the feature vectors, *e.g.*, PT08.S1(CO) is $x_1$ up until AH which is $x_D$. The original dataset also has a date and a time columns that we are not going to use in this assignment.\n",
    "\n",
    "Before designing our predictive model, we need to think about three stages: the preprocessing stage, the training stage and the validation stage. The three stages are interconnected and *it is important to remember that the testing data that we use for validation has to be set aside before preprocessing*. Any preprocessing that you do has to be done only on the training data and several key statistics need to be saved for the test stage.\n",
    "\n",
    "Separating the dataset into training and test before any preprocessing has happened help us to recreate the real world scenario where we will deploy our system and for which the data will come without any preprocessing.\n",
    "\n",
    "We are going to use *hold-out validation* for testing our predictive model so we need to separate the dataset into a training set and a test set.\n",
    "\n",
    "### Question 3: Splitting the dataset (1 mark)\n",
    "\n",
    "Split the dataset into a training set and a test set. The training set should have 70% of the total observations and the test set, the 30%. For making the random selection make sure that you use a random seed that corresponds to the last five digits of your student UCard. Make sure that you comment your code.\n",
    "\n",
    "#### Question 3 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MyStudentID = 14433\n",
    "training_number = round(0.7 * air_quality.shape[0])      # the number of training data\n",
    "test_number = air_quality.shape[0] - training_number     # the number of test data\n",
    "\n",
    "\n",
    "# generate a random sequence for the data according to UCard number\n",
    "np.random.seed(MyStudentID)\n",
    "rearranged_air_quality = air_quality.reindex(np.random.permutation(air_quality.index)) \n",
    "\n",
    "\n",
    "training_data = rearranged_air_quality[0:training_number]   # the training data for Q3         \n",
    "test_data = rearranged_air_quality[training_number:air_quality.shape[0]] # the test data for Q3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "The dataset has missing values tagged with a -200 value. Before doing any work with the training data, we want to make sure that we deal properly with the missing values. \n",
    "\n",
    "### Question 4: Missing values (3 marks)\n",
    "\n",
    "Make some exploratory analysis on the number of missing values per column in the training data. \n",
    "\n",
    "* Remove the rows for which the target feature has missing values. We are doing supervised learning so we need all our data observations to have known target values.\n",
    "\n",
    "* Remove features with more than 20% of missing values. For all the other features with missing values, use the mean value of the non-missing values for imputation.\n",
    "\n",
    "#### Question 4 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_training_data = training_data[training_data['CO(GT)']!= -200] # Remove the rows that the target feature equals to -200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = preprocessed_training_data.shape[0] # obtain the rows number of training data\n",
    "col_total = preprocessed_training_data.shape[1] #obtain the column number of training data\n",
    "selected_data = preprocessed_training_data.copy()  # In the next few steps, it may change the original data, just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the whole columns, put all the columns that should be removed into a list,then delete the columns shown in the list\n",
    "col_list = []\n",
    "for col_number in range(col_total):\n",
    "    if ((selected_data.iloc[:,col_number] == -200).sum())/total > 0.2:\n",
    "        col_list.append(selected_data.columns[col_number])\n",
    "\n",
    "selected_data.drop(columns=col_list,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranfer -200 into NaN\n",
    "for j in range(selected_data.shape[1]):\n",
    "    for i in range(selected_data.shape[0]):\n",
    "        if selected_data.iloc[i,j] == -200:\n",
    "            selected_data.iloc[i,j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data.fillna(selected_data.mean(),inplace=True) # use fillna() to fill NaNs with mean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Normalising the training data (2 marks)\n",
    "\n",
    "Now that you have removed the missing data, we need to normalise the input vectors. \n",
    "\n",
    "* Explain in a sentence why do you need to normalise the input features for this dataset.\n",
    "\n",
    "* Normalise the training data by substracting the mean value for each feature and dividing the result by the standard deviation of each feature. Keep the mean values and standard deviations, you will need them at test time.\n",
    "\n",
    "#### Question 5 Answer\n",
    "\n",
    "We can speed up gradient descent by having each of our input values in roughly the same range,or oscillate would inefficiently down to the optimum when the variables are very uneven\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = selected_data.iloc[:,1:12] # We should only normalise the input features X, target y (CO(GT)) stay the same\n",
    "normalised_data = (input_features - input_features.mean())/input_features.std()\n",
    "normalised_data.insert(0,'CO(GT)',selected_data.iloc[:,0]) #put y back to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.9</td>\n",
       "      <td>8.068445e-01</td>\n",
       "      <td>-4.190658e-01</td>\n",
       "      <td>-3.083908e-01</td>\n",
       "      <td>-5.317886e-01</td>\n",
       "      <td>1.325301e+00</td>\n",
       "      <td>-6.563652e-02</td>\n",
       "      <td>2.687408e-01</td>\n",
       "      <td>-6.222881e-01</td>\n",
       "      <td>-1.084921e+00</td>\n",
       "      <td>1.599036e+00</td>\n",
       "      <td>-3.810828e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.340723e+00</td>\n",
       "      <td>-1.082963e+00</td>\n",
       "      <td>-1.281608e+00</td>\n",
       "      <td>4.932953e-15</td>\n",
       "      <td>1.581584e+00</td>\n",
       "      <td>1.445833e-14</td>\n",
       "      <td>-1.793733e-01</td>\n",
       "      <td>-1.186147e+00</td>\n",
       "      <td>-4.343811e-01</td>\n",
       "      <td>1.084436e+00</td>\n",
       "      <td>2.067628e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-6.159192e-01</td>\n",
       "      <td>-2.388378e-01</td>\n",
       "      <td>-9.970696e-02</td>\n",
       "      <td>-1.364510e-01</td>\n",
       "      <td>-3.789832e-01</td>\n",
       "      <td>-1.295012e+00</td>\n",
       "      <td>-5.875533e-02</td>\n",
       "      <td>-2.264543e-01</td>\n",
       "      <td>-2.348824e-01</td>\n",
       "      <td>1.631382e+00</td>\n",
       "      <td>9.363896e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>2.2</td>\n",
       "      <td>-1.070390e-01</td>\n",
       "      <td>2.917797e-01</td>\n",
       "      <td>4.465255e-01</td>\n",
       "      <td>-3.871529e-01</td>\n",
       "      <td>-3.858831e-01</td>\n",
       "      <td>-1.292249e-01</td>\n",
       "      <td>9.588220e-01</td>\n",
       "      <td>4.569726e-01</td>\n",
       "      <td>4.937217e-01</td>\n",
       "      <td>-5.813948e-01</td>\n",
       "      <td>8.791423e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.389744e+00</td>\n",
       "      <td>-9.663456e-01</td>\n",
       "      <td>-1.072924e+00</td>\n",
       "      <td>-1.023550e+00</td>\n",
       "      <td>5.692651e-01</td>\n",
       "      <td>-1.506974e+00</td>\n",
       "      <td>2.723959e-01</td>\n",
       "      <td>-6.845895e-01</td>\n",
       "      <td>5.660039e-01</td>\n",
       "      <td>8.330178e-01</td>\n",
       "      <td>1.834906e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4418</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1.100521e-01</td>\n",
       "      <td>3.608575e-01</td>\n",
       "      <td>5.119195e-01</td>\n",
       "      <td>2.444230e-01</td>\n",
       "      <td>-1.032948e-02</td>\n",
       "      <td>9.305819e-01</td>\n",
       "      <td>9.548951e-02</td>\n",
       "      <td>2.102844e-01</td>\n",
       "      <td>1.158718e+00</td>\n",
       "      <td>-1.128340e+00</td>\n",
       "      <td>2.774689e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334</th>\n",
       "      <td>3.4</td>\n",
       "      <td>9.247274e-01</td>\n",
       "      <td>1.599545e+00</td>\n",
       "      <td>1.542837e+00</td>\n",
       "      <td>-1.171663e-01</td>\n",
       "      <td>-1.172476e+00</td>\n",
       "      <td>-8.922858e-01</td>\n",
       "      <td>1.498313e+00</td>\n",
       "      <td>1.107046e+00</td>\n",
       "      <td>9.360885e-01</td>\n",
       "      <td>-4.328962e-01</td>\n",
       "      <td>9.609484e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-2.653807e-14</td>\n",
       "      <td>7.082285e-15</td>\n",
       "      <td>-3.498560e-15</td>\n",
       "      <td>2.276072e+00</td>\n",
       "      <td>1.792987e-15</td>\n",
       "      <td>1.596141e+00</td>\n",
       "      <td>-1.329714e-14</td>\n",
       "      <td>-1.602583e-14</td>\n",
       "      <td>-5.341394e-15</td>\n",
       "      <td>-1.295427e-14</td>\n",
       "      <td>1.969678e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.774439e-01</td>\n",
       "      <td>-1.014330e+00</td>\n",
       "      <td>-1.155628e+00</td>\n",
       "      <td>-6.320693e-01</td>\n",
       "      <td>-7.144319e-02</td>\n",
       "      <td>-4.514062e-01</td>\n",
       "      <td>-9.820313e-01</td>\n",
       "      <td>-8.482092e-01</td>\n",
       "      <td>-6.252060e-01</td>\n",
       "      <td>9.756353e-01</td>\n",
       "      <td>-1.324526e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7746</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.053603e+00</td>\n",
       "      <td>-1.012149e+00</td>\n",
       "      <td>-1.151781e+00</td>\n",
       "      <td>-4.344006e-01</td>\n",
       "      <td>7.200780e-01</td>\n",
       "      <td>-2.352056e-01</td>\n",
       "      <td>-1.729132e+00</td>\n",
       "      <td>-1.153423e+00</td>\n",
       "      <td>-1.281528e+00</td>\n",
       "      <td>-5.299350e-01</td>\n",
       "      <td>-1.508633e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.483364e-02</td>\n",
       "      <td>-1.524172e-01</td>\n",
       "      <td>-4.500946e-03</td>\n",
       "      <td>-7.487421e-01</td>\n",
       "      <td>2.932677e-01</td>\n",
       "      <td>-6.167361e-01</td>\n",
       "      <td>5.472587e-01</td>\n",
       "      <td>-3.913326e-01</td>\n",
       "      <td>9.621102e-01</td>\n",
       "      <td>-1.019539e+00</td>\n",
       "      <td>1.697206e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6694</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.153743e+00</td>\n",
       "      <td>2.316186e+00</td>\n",
       "      <td>2.055411e+00</td>\n",
       "      <td>2.500740e+00</td>\n",
       "      <td>-1.443545e+00</td>\n",
       "      <td>1.502878e+00</td>\n",
       "      <td>9.727113e-01</td>\n",
       "      <td>2.303987e+00</td>\n",
       "      <td>-1.018833e-01</td>\n",
       "      <td>-5.209279e-02</td>\n",
       "      <td>-1.827517e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.340723e+00</td>\n",
       "      <td>-1.050636e+00</td>\n",
       "      <td>-1.221022e+00</td>\n",
       "      <td>-1.119974e+00</td>\n",
       "      <td>7.959773e-01</td>\n",
       "      <td>-1.740131e+00</td>\n",
       "      <td>8.233118e-02</td>\n",
       "      <td>-1.140207e+00</td>\n",
       "      <td>8.175458e-01</td>\n",
       "      <td>3.639974e-01</td>\n",
       "      <td>1.814177e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>8.1</td>\n",
       "      <td>3.534489e+00</td>\n",
       "      <td>4.763250e+00</td>\n",
       "      <td>3.548895e+00</td>\n",
       "      <td>3.590329e+00</td>\n",
       "      <td>-1.872326e+00</td>\n",
       "      <td>1.375701e+00</td>\n",
       "      <td>3.034914e+00</td>\n",
       "      <td>2.814984e+00</td>\n",
       "      <td>6.209383e-01</td>\n",
       "      <td>2.904833e-01</td>\n",
       "      <td>1.310167e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>5.7</td>\n",
       "      <td>1.886464e+00</td>\n",
       "      <td>2.479275e+00</td>\n",
       "      <td>2.166004e+00</td>\n",
       "      <td>2.276072e+00</td>\n",
       "      <td>-1.597315e+00</td>\n",
       "      <td>1.411734e+00</td>\n",
       "      <td>1.336027e+00</td>\n",
       "      <td>1.746422e+00</td>\n",
       "      <td>-4.112508e-01</td>\n",
       "      <td>5.022040e-01</td>\n",
       "      <td>-1.606924e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9007</th>\n",
       "      <td>1.6</td>\n",
       "      <td>-8.369588e-02</td>\n",
       "      <td>-7.780538e-01</td>\n",
       "      <td>-7.796125e-01</td>\n",
       "      <td>-3.847423e-01</td>\n",
       "      <td>-4.331969e-01</td>\n",
       "      <td>-2.436841e-01</td>\n",
       "      <td>-6.676935e-01</td>\n",
       "      <td>-3.277727e-01</td>\n",
       "      <td>-5.008807e-01</td>\n",
       "      <td>1.007982e+00</td>\n",
       "      <td>5.862152e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>2.3</td>\n",
       "      <td>1.380639e-01</td>\n",
       "      <td>1.737117e-01</td>\n",
       "      <td>3.320860e-01</td>\n",
       "      <td>-7.535633e-01</td>\n",
       "      <td>-3.149123e-01</td>\n",
       "      <td>-6.563652e-02</td>\n",
       "      <td>4.865842e-01</td>\n",
       "      <td>4.037165e-02</td>\n",
       "      <td>1.187630e+00</td>\n",
       "      <td>-1.270958e+00</td>\n",
       "      <td>9.005318e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1.783755e+00</td>\n",
       "      <td>1.933030e-01</td>\n",
       "      <td>3.513195e-01</td>\n",
       "      <td>-4.257224e-01</td>\n",
       "      <td>-6.848607e-02</td>\n",
       "      <td>-2.140095e-01</td>\n",
       "      <td>8.484382e-01</td>\n",
       "      <td>8.225997e-01</td>\n",
       "      <td>-6.140524e-02</td>\n",
       "      <td>-8.149841e-02</td>\n",
       "      <td>-1.559935e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1.579055e-01</td>\n",
       "      <td>-2.949987e-01</td>\n",
       "      <td>-1.631776e-01</td>\n",
       "      <td>-5.028615e-01</td>\n",
       "      <td>-4.285774e-02</td>\n",
       "      <td>-7.439129e-01</td>\n",
       "      <td>7.073517e-01</td>\n",
       "      <td>2.014741e-01</td>\n",
       "      <td>-2.001869e-01</td>\n",
       "      <td>9.756354e-01</td>\n",
       "      <td>4.935452e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.544762e-01</td>\n",
       "      <td>3.343077e-01</td>\n",
       "      <td>4.869159e-01</td>\n",
       "      <td>-4.064377e-01</td>\n",
       "      <td>-1.453711e-01</td>\n",
       "      <td>7.610128e-01</td>\n",
       "      <td>4.639227e-01</td>\n",
       "      <td>-3.252554e-01</td>\n",
       "      <td>2.604361e+00</td>\n",
       "      <td>-2.078143e+00</td>\n",
       "      <td>7.697563e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7442</th>\n",
       "      <td>5.8</td>\n",
       "      <td>1.790757e+00</td>\n",
       "      <td>2.117549e+00</td>\n",
       "      <td>1.917891e+00</td>\n",
       "      <td>2.212915e+00</td>\n",
       "      <td>-1.543101e+00</td>\n",
       "      <td>1.549509e+00</td>\n",
       "      <td>7.753364e-01</td>\n",
       "      <td>1.886757e+00</td>\n",
       "      <td>-1.082029e+00</td>\n",
       "      <td>1.516700e+00</td>\n",
       "      <td>-4.165848e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6925</th>\n",
       "      <td>3.9</td>\n",
       "      <td>4.473603e-01</td>\n",
       "      <td>-1.158665e-01</td>\n",
       "      <td>3.492781e-02</td>\n",
       "      <td>5.915487e-01</td>\n",
       "      <td>-6.332951e-01</td>\n",
       "      <td>4.854630e-01</td>\n",
       "      <td>-9.374392e-01</td>\n",
       "      <td>1.550078e+00</td>\n",
       "      <td>-1.428984e+00</td>\n",
       "      <td>6.992220e-01</td>\n",
       "      <td>-1.114386e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-8.773623e-01</td>\n",
       "      <td>-5.162860e-01</td>\n",
       "      <td>-4.276388e-01</td>\n",
       "      <td>-2.232324e-01</td>\n",
       "      <td>4.844945e-01</td>\n",
       "      <td>-6.803245e-01</td>\n",
       "      <td>-3.540867e-01</td>\n",
       "      <td>-8.016405e-01</td>\n",
       "      <td>8.927193e-01</td>\n",
       "      <td>-8.504568e-01</td>\n",
       "      <td>3.098762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>8.3</td>\n",
       "      <td>2.380172e+00</td>\n",
       "      <td>2.680353e+00</td>\n",
       "      <td>2.299677e+00</td>\n",
       "      <td>2.775548e+00</td>\n",
       "      <td>-1.624914e+00</td>\n",
       "      <td>1.545270e+00</td>\n",
       "      <td>1.738818e+00</td>\n",
       "      <td>2.105756e+00</td>\n",
       "      <td>-1.683828e-01</td>\n",
       "      <td>7.844985e-01</td>\n",
       "      <td>3.950262e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.8</td>\n",
       "      <td>-9.310515e-01</td>\n",
       "      <td>-1.061035e+00</td>\n",
       "      <td>-1.240256e+00</td>\n",
       "      <td>-9.415897e-01</td>\n",
       "      <td>1.753097e+00</td>\n",
       "      <td>-9.982665e-01</td>\n",
       "      <td>-6.157912e-01</td>\n",
       "      <td>-1.441016e+00</td>\n",
       "      <td>-8.594002e-01</td>\n",
       "      <td>5.139663e-01</td>\n",
       "      <td>-6.735410e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>1.9</td>\n",
       "      <td>-4.828634e-01</td>\n",
       "      <td>-2.611012e-01</td>\n",
       "      <td>-1.247106e-01</td>\n",
       "      <td>-7.390998e-01</td>\n",
       "      <td>7.447206e-01</td>\n",
       "      <td>-6.379322e-01</td>\n",
       "      <td>-1.589048e-01</td>\n",
       "      <td>-7.758389e-01</td>\n",
       "      <td>-1.539264e-01</td>\n",
       "      <td>-1.084232e+00</td>\n",
       "      <td>-1.067955e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>2.8</td>\n",
       "      <td>2.080933e-01</td>\n",
       "      <td>6.948125e-01</td>\n",
       "      <td>8.138861e-01</td>\n",
       "      <td>-4.353648e-01</td>\n",
       "      <td>-3.474406e-01</td>\n",
       "      <td>1.887171e-01</td>\n",
       "      <td>1.435446e+00</td>\n",
       "      <td>-1.175843e-01</td>\n",
       "      <td>1.586628e+00</td>\n",
       "      <td>-1.115108e+00</td>\n",
       "      <td>9.612742e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>0.9</td>\n",
       "      <td>-7.396378e-01</td>\n",
       "      <td>-3.843663e-01</td>\n",
       "      <td>-2.670387e-01</td>\n",
       "      <td>-8.596295e-01</td>\n",
       "      <td>4.289860e-02</td>\n",
       "      <td>-7.015206e-01</td>\n",
       "      <td>3.074848e-01</td>\n",
       "      <td>-5.354438e-01</td>\n",
       "      <td>4.561350e-01</td>\n",
       "      <td>-3.049816e-01</td>\n",
       "      <td>3.415314e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>2.9</td>\n",
       "      <td>-2.611037e-01</td>\n",
       "      <td>3.813961e-01</td>\n",
       "      <td>5.311531e-01</td>\n",
       "      <td>4.932953e-15</td>\n",
       "      <td>1.779402e-01</td>\n",
       "      <td>1.445833e-14</td>\n",
       "      <td>9.485877e-01</td>\n",
       "      <td>-1.641530e-01</td>\n",
       "      <td>7.799591e-01</td>\n",
       "      <td>-8.239917e-01</td>\n",
       "      <td>1.864843e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>0.8</td>\n",
       "      <td>-9.543946e-01</td>\n",
       "      <td>-8.147030e-01</td>\n",
       "      <td>-8.334664e-01</td>\n",
       "      <td>-8.644507e-01</td>\n",
       "      <td>5.495510e-01</td>\n",
       "      <td>-1.125443e+00</td>\n",
       "      <td>-3.920996e-01</td>\n",
       "      <td>-8.167439e-01</td>\n",
       "      <td>6.729814e-01</td>\n",
       "      <td>-2.696947e-01</td>\n",
       "      <td>7.246114e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.198095e+00</td>\n",
       "      <td>1.855505e+00</td>\n",
       "      <td>1.731326e+00</td>\n",
       "      <td>-5.931198e-02</td>\n",
       "      <td>-7.249656e-01</td>\n",
       "      <td>3.158939e-01</td>\n",
       "      <td>1.467611e+00</td>\n",
       "      <td>1.582802e+00</td>\n",
       "      <td>-5.037720e-01</td>\n",
       "      <td>-8.048779e-01</td>\n",
       "      <td>-1.135617e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8463</th>\n",
       "      <td>1.5</td>\n",
       "      <td>-8.388461e-01</td>\n",
       "      <td>-8.610883e-01</td>\n",
       "      <td>-9.036688e-01</td>\n",
       "      <td>-1.407901e-01</td>\n",
       "      <td>2.853820e-01</td>\n",
       "      <td>3.858412e-01</td>\n",
       "      <td>-1.514944e+00</td>\n",
       "      <td>-8.570195e-01</td>\n",
       "      <td>-1.267072e+00</td>\n",
       "      <td>1.406991e-02</td>\n",
       "      <td>-1.268429e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>1.5</td>\n",
       "      <td>-6.579369e-01</td>\n",
       "      <td>-6.303465e-01</td>\n",
       "      <td>-5.747753e-01</td>\n",
       "      <td>-2.762655e-01</td>\n",
       "      <td>2.712732e-02</td>\n",
       "      <td>-9.134820e-01</td>\n",
       "      <td>-5.729330e-02</td>\n",
       "      <td>-5.574696e-01</td>\n",
       "      <td>2.306147e-01</td>\n",
       "      <td>1.141777e+00</td>\n",
       "      <td>1.436154e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>0.7</td>\n",
       "      <td>-1.669862e+00</td>\n",
       "      <td>-1.223874e+00</td>\n",
       "      <td>-1.581651e+00</td>\n",
       "      <td>-7.530812e-01</td>\n",
       "      <td>1.807311e+00</td>\n",
       "      <td>-7.735875e-01</td>\n",
       "      <td>-2.408248e+00</td>\n",
       "      <td>-1.770773e+00</td>\n",
       "      <td>-1.926285e+00</td>\n",
       "      <td>-8.813327e-01</td>\n",
       "      <td>-1.927164e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.878354e-01</td>\n",
       "      <td>1.364906e+00</td>\n",
       "      <td>1.363965e+00</td>\n",
       "      <td>-1.846629e-01</td>\n",
       "      <td>-6.806089e-01</td>\n",
       "      <td>5.066592e-01</td>\n",
       "      <td>1.671565e+00</td>\n",
       "      <td>3.833437e-01</td>\n",
       "      <td>1.618432e+00</td>\n",
       "      <td>-1.373878e+00</td>\n",
       "      <td>5.035284e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8627</th>\n",
       "      <td>1.1</td>\n",
       "      <td>-6.427638e-01</td>\n",
       "      <td>-9.403281e-01</td>\n",
       "      <td>-1.029649e+00</td>\n",
       "      <td>-5.824111e-01</td>\n",
       "      <td>2.459538e-01</td>\n",
       "      <td>-1.080288e-01</td>\n",
       "      <td>-1.452076e+00</td>\n",
       "      <td>-5.883056e-01</td>\n",
       "      <td>-1.564874e+00</td>\n",
       "      <td>7.800877e-01</td>\n",
       "      <td>-1.192485e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-4.945350e-01</td>\n",
       "      <td>-7.647422e-01</td>\n",
       "      <td>-7.603790e-01</td>\n",
       "      <td>-9.801593e-01</td>\n",
       "      <td>8.824103e-02</td>\n",
       "      <td>-1.083051e+00</td>\n",
       "      <td>5.962370e-01</td>\n",
       "      <td>-1.014346e+00</td>\n",
       "      <td>1.147152e+00</td>\n",
       "      <td>1.860931e-01</td>\n",
       "      <td>2.321216e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.711918e-01</td>\n",
       "      <td>-5.565401e-01</td>\n",
       "      <td>-4.786077e-01</td>\n",
       "      <td>-1.086225e+00</td>\n",
       "      <td>-9.312870e-02</td>\n",
       "      <td>-1.612954e+00</td>\n",
       "      <td>4.880463e-01</td>\n",
       "      <td>-8.469506e-01</td>\n",
       "      <td>1.534585e+00</td>\n",
       "      <td>-3.726146e-01</td>\n",
       "      <td>2.284224e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>1.9</td>\n",
       "      <td>-4.015515e-01</td>\n",
       "      <td>2.954747e-01</td>\n",
       "      <td>4.500517e-01</td>\n",
       "      <td>-7.101726e-01</td>\n",
       "      <td>4.421287e-02</td>\n",
       "      <td>-1.080288e-01</td>\n",
       "      <td>7.139309e-01</td>\n",
       "      <td>-5.853688e-01</td>\n",
       "      <td>2.272827e+00</td>\n",
       "      <td>-1.919353e+00</td>\n",
       "      <td>1.365696e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>3.1</td>\n",
       "      <td>5.955892e-01</td>\n",
       "      <td>6.074100e-01</td>\n",
       "      <td>7.369519e-01</td>\n",
       "      <td>1.606891e+00</td>\n",
       "      <td>-1.021663e+00</td>\n",
       "      <td>1.032323e+00</td>\n",
       "      <td>-1.676770e-01</td>\n",
       "      <td>9.736333e-01</td>\n",
       "      <td>-8.622915e-01</td>\n",
       "      <td>8.447801e-01</td>\n",
       "      <td>-4.988233e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>3.6</td>\n",
       "      <td>7.193078e-01</td>\n",
       "      <td>1.612389e+00</td>\n",
       "      <td>1.552454e+00</td>\n",
       "      <td>-3.292986e-01</td>\n",
       "      <td>-6.914517e-01</td>\n",
       "      <td>1.887171e-01</td>\n",
       "      <td>1.507817e+00</td>\n",
       "      <td>3.776800e-01</td>\n",
       "      <td>3.867442e-01</td>\n",
       "      <td>-6.740227e-01</td>\n",
       "      <td>-1.516156e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>1.9</td>\n",
       "      <td>-6.672741e-01</td>\n",
       "      <td>1.251809e-01</td>\n",
       "      <td>2.840021e-01</td>\n",
       "      <td>-5.896429e-01</td>\n",
       "      <td>-1.542424e-01</td>\n",
       "      <td>1.675210e-01</td>\n",
       "      <td>3.133329e-01</td>\n",
       "      <td>6.869045e-02</td>\n",
       "      <td>1.002588e+00</td>\n",
       "      <td>-1.288601e+00</td>\n",
       "      <td>-1.667946e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.7</td>\n",
       "      <td>-7.092918e-01</td>\n",
       "      <td>-1.070797e+00</td>\n",
       "      <td>-1.258528e+00</td>\n",
       "      <td>4.932953e-15</td>\n",
       "      <td>2.189764e+00</td>\n",
       "      <td>1.445833e-14</td>\n",
       "      <td>-4.213404e-01</td>\n",
       "      <td>-1.550515e+00</td>\n",
       "      <td>-5.962931e-01</td>\n",
       "      <td>1.074144e+00</td>\n",
       "      <td>-3.245601e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.160981e+00</td>\n",
       "      <td>-1.131178e+00</td>\n",
       "      <td>-1.376814e+00</td>\n",
       "      <td>-1.105510e+00</td>\n",
       "      <td>1.658469e+00</td>\n",
       "      <td>-1.655347e+00</td>\n",
       "      <td>-2.086141e-01</td>\n",
       "      <td>-1.357947e+00</td>\n",
       "      <td>-3.579463e-03</td>\n",
       "      <td>4.007545e-01</td>\n",
       "      <td>3.341430e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.371070e+00</td>\n",
       "      <td>-9.490695e-01</td>\n",
       "      <td>-1.044074e+00</td>\n",
       "      <td>-9.656957e-01</td>\n",
       "      <td>8.748337e-01</td>\n",
       "      <td>-1.125443e+00</td>\n",
       "      <td>-1.939937e-01</td>\n",
       "      <td>-9.092519e-01</td>\n",
       "      <td>3.000056e-01</td>\n",
       "      <td>-1.447207e-01</td>\n",
       "      <td>2.796915e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-6.030805e-01</td>\n",
       "      <td>-8.282085e-01</td>\n",
       "      <td>-8.536616e-01</td>\n",
       "      <td>-2.849437e-01</td>\n",
       "      <td>2.558109e-01</td>\n",
       "      <td>4.579080e-01</td>\n",
       "      <td>-1.569039e+00</td>\n",
       "      <td>-3.346950e-01</td>\n",
       "      <td>-1.570657e+00</td>\n",
       "      <td>-3.726146e-01</td>\n",
       "      <td>-1.608166e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>2.2</td>\n",
       "      <td>-1.735669e-01</td>\n",
       "      <td>-3.050841e-01</td>\n",
       "      <td>-1.747178e-01</td>\n",
       "      <td>2.878137e-01</td>\n",
       "      <td>3.157727e+00</td>\n",
       "      <td>-2.775979e-01</td>\n",
       "      <td>-3.365422e-01</td>\n",
       "      <td>-2.214199e-01</td>\n",
       "      <td>-6.974882e-01</td>\n",
       "      <td>1.869568e+00</td>\n",
       "      <td>3.004166e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>1.9</td>\n",
       "      <td>-2.653807e-14</td>\n",
       "      <td>7.082285e-15</td>\n",
       "      <td>-3.498560e-15</td>\n",
       "      <td>-6.523183e-01</td>\n",
       "      <td>1.792987e-15</td>\n",
       "      <td>-6.803245e-01</td>\n",
       "      <td>-1.329714e-14</td>\n",
       "      <td>-1.602583e-14</td>\n",
       "      <td>-5.341394e-15</td>\n",
       "      <td>-1.295427e-14</td>\n",
       "      <td>1.969678e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7139</th>\n",
       "      <td>1.1</td>\n",
       "      <td>-8.878667e-01</td>\n",
       "      <td>-1.045914e+00</td>\n",
       "      <td>-1.212367e+00</td>\n",
       "      <td>-6.446044e-01</td>\n",
       "      <td>6.205218e-01</td>\n",
       "      <td>-8.477740e-01</td>\n",
       "      <td>-1.468889e+00</td>\n",
       "      <td>-4.316083e-01</td>\n",
       "      <td>-1.689199e+00</td>\n",
       "      <td>1.172653e+00</td>\n",
       "      <td>-1.155438e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>3.8</td>\n",
       "      <td>-2.653807e-14</td>\n",
       "      <td>7.082285e-15</td>\n",
       "      <td>-3.498560e-15</td>\n",
       "      <td>1.327744e+00</td>\n",
       "      <td>1.792987e-15</td>\n",
       "      <td>1.458366e+00</td>\n",
       "      <td>-1.329714e-14</td>\n",
       "      <td>-1.602583e-14</td>\n",
       "      <td>-5.341394e-15</td>\n",
       "      <td>-1.295427e-14</td>\n",
       "      <td>1.969678e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.423163e-01</td>\n",
       "      <td>-3.193054e-01</td>\n",
       "      <td>-1.910663e-01</td>\n",
       "      <td>1.913899e-01</td>\n",
       "      <td>-5.169819e-01</td>\n",
       "      <td>4.034416e-02</td>\n",
       "      <td>-3.299631e-01</td>\n",
       "      <td>-3.026004e-01</td>\n",
       "      <td>-6.107496e-01</td>\n",
       "      <td>1.374082e+00</td>\n",
       "      <td>1.332570e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.135069e+00</td>\n",
       "      <td>3.099936e+00</td>\n",
       "      <td>2.569908e+00</td>\n",
       "      <td>2.833402e+00</td>\n",
       "      <td>-1.579572e+00</td>\n",
       "      <td>7.610128e-01</td>\n",
       "      <td>2.119679e+00</td>\n",
       "      <td>2.260565e+00</td>\n",
       "      <td>5.081782e-01</td>\n",
       "      <td>4.345711e-01</td>\n",
       "      <td>1.255877e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.388148e-01</td>\n",
       "      <td>-6.070351e-01</td>\n",
       "      <td>-5.440017e-01</td>\n",
       "      <td>4.932953e-15</td>\n",
       "      <td>-5.564101e-01</td>\n",
       "      <td>1.445833e-14</td>\n",
       "      <td>-1.153090e+00</td>\n",
       "      <td>1.059848e+00</td>\n",
       "      <td>-1.472353e+00</td>\n",
       "      <td>1.000630e+00</td>\n",
       "      <td>-1.035455e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7960</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-6.859486e-01</td>\n",
       "      <td>-7.398089e-01</td>\n",
       "      <td>-7.247969e-01</td>\n",
       "      <td>2.188707e-01</td>\n",
       "      <td>1.996257e-01</td>\n",
       "      <td>1.801743e+00</td>\n",
       "      <td>-1.623865e+00</td>\n",
       "      <td>-2.667299e-01</td>\n",
       "      <td>-1.174550e+00</td>\n",
       "      <td>-5.887463e-01</td>\n",
       "      <td>-1.471275e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.9</td>\n",
       "      <td>-8.306760e-01</td>\n",
       "      <td>-1.083466e+00</td>\n",
       "      <td>-1.282570e+00</td>\n",
       "      <td>-9.753381e-01</td>\n",
       "      <td>2.156250e+00</td>\n",
       "      <td>-1.189032e+00</td>\n",
       "      <td>-5.704681e-01</td>\n",
       "      <td>-8.287007e-01</td>\n",
       "      <td>-1.313332e+00</td>\n",
       "      <td>1.021214e+00</td>\n",
       "      <td>-8.835309e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>3.1</td>\n",
       "      <td>-5.568412e-02</td>\n",
       "      <td>5.804200e-01</td>\n",
       "      <td>7.129100e-01</td>\n",
       "      <td>8.229658e-01</td>\n",
       "      <td>-5.633100e-01</td>\n",
       "      <td>1.121347e+00</td>\n",
       "      <td>-4.732426e-01</td>\n",
       "      <td>5.903856e-01</td>\n",
       "      <td>-4.777504e-01</td>\n",
       "      <td>-8.975058e-01</td>\n",
       "      <td>-1.177419e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>2.4</td>\n",
       "      <td>-1.280478e-01</td>\n",
       "      <td>7.113754e-01</td>\n",
       "      <td>8.283112e-01</td>\n",
       "      <td>5.385156e-01</td>\n",
       "      <td>-4.686823e-01</td>\n",
       "      <td>1.039326e-01</td>\n",
       "      <td>1.700534e-01</td>\n",
       "      <td>2.725858e-01</td>\n",
       "      <td>-4.864243e-01</td>\n",
       "      <td>5.242584e-01</td>\n",
       "      <td>-2.414014e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8336</th>\n",
       "      <td>0.8</td>\n",
       "      <td>-9.485589e-01</td>\n",
       "      <td>-1.254656e+00</td>\n",
       "      <td>-1.658585e+00</td>\n",
       "      <td>-9.184480e-01</td>\n",
       "      <td>1.196174e+00</td>\n",
       "      <td>-1.197510e+00</td>\n",
       "      <td>-1.489358e+00</td>\n",
       "      <td>-1.616592e+00</td>\n",
       "      <td>-1.382723e+00</td>\n",
       "      <td>1.238816e+00</td>\n",
       "      <td>-8.612219e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8179</th>\n",
       "      <td>1.1</td>\n",
       "      <td>-6.649398e-01</td>\n",
       "      <td>-4.564141e-01</td>\n",
       "      <td>-3.535897e-01</td>\n",
       "      <td>-4.536853e-01</td>\n",
       "      <td>-3.089981e-01</td>\n",
       "      <td>1.124110e-01</td>\n",
       "      <td>-1.329265e+00</td>\n",
       "      <td>-8.891141e-01</td>\n",
       "      <td>-6.599015e-01</td>\n",
       "      <td>-6.210925e-01</td>\n",
       "      <td>-1.139101e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-9.205471e-01</td>\n",
       "      <td>-1.218256e+00</td>\n",
       "      <td>-1.568188e+00</td>\n",
       "      <td>4.932953e-15</td>\n",
       "      <td>1.248416e+00</td>\n",
       "      <td>1.445833e-14</td>\n",
       "      <td>-1.112884e+00</td>\n",
       "      <td>-1.283689e+00</td>\n",
       "      <td>-6.917056e-01</td>\n",
       "      <td>1.462299e+00</td>\n",
       "      <td>6.869986e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5381 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CO(GT)   PT08.S1(CO)      C6H6(GT)  PT08.S2(NMHC)       NOx(GT)  \\\n",
       "19       1.9  8.068445e-01 -4.190658e-01  -3.083908e-01 -5.317886e-01   \n",
       "1377     0.6 -1.340723e+00 -1.082963e+00  -1.281608e+00  4.932953e-15   \n",
       "5508     1.4 -6.159192e-01 -2.388378e-01  -9.970696e-02 -1.364510e-01   \n",
       "2582     2.2 -1.070390e-01  2.917797e-01   4.465255e-01 -3.871529e-01   \n",
       "3588     0.6 -1.389744e+00 -9.663456e-01  -1.072924e+00 -1.023550e+00   \n",
       "4418     2.6  1.100521e-01  3.608575e-01   5.119195e-01  2.444230e-01   \n",
       "4334     3.4  9.247274e-01  1.599545e+00   1.542837e+00 -1.171663e-01   \n",
       "7177     5.0 -2.653807e-14  7.082285e-15  -3.498560e-15  2.276072e+00   \n",
       "8961     1.0 -2.774439e-01 -1.014330e+00  -1.155628e+00 -6.320693e-01   \n",
       "7746     1.0 -1.053603e+00 -1.012149e+00  -1.151781e+00 -4.344006e-01   \n",
       "1242     2.0 -1.483364e-02 -1.524172e-01  -4.500946e-03 -7.487421e-01   \n",
       "6694     5.1  2.153743e+00  2.316186e+00   2.055411e+00  2.500740e+00   \n",
       "3776     0.5 -1.340723e+00 -1.050636e+00  -1.221022e+00 -1.119974e+00   \n",
       "5759     8.1  3.534489e+00  4.763250e+00   3.548895e+00  3.590329e+00   \n",
       "7393     5.7  1.886464e+00  2.479275e+00   2.166004e+00  2.276072e+00   \n",
       "9007     1.6 -8.369588e-02 -7.780538e-01  -7.796125e-01 -3.847423e-01   \n",
       "3100     2.3  1.380639e-01  1.737117e-01   3.320860e-01 -7.535633e-01   \n",
       "235      2.6  1.783755e+00  1.933030e-01   3.513195e-01 -4.257224e-01   \n",
       "1284     1.3  1.579055e-01 -2.949987e-01  -1.631776e-01 -5.028615e-01   \n",
       "2829     2.0 -3.544762e-01  3.343077e-01   4.869159e-01 -4.064377e-01   \n",
       "7442     5.8  1.790757e+00  2.117549e+00   1.917891e+00  2.212915e+00   \n",
       "6925     3.9  4.473603e-01 -1.158665e-01   3.492781e-02  5.915487e-01   \n",
       "4600     1.4 -8.773623e-01 -5.162860e-01  -4.276388e-01 -2.232324e-01   \n",
       "6097     8.3  2.380172e+00  2.680353e+00   2.299677e+00  2.775548e+00   \n",
       "796      0.8 -9.310515e-01 -1.061035e+00  -1.240256e+00 -9.415897e-01   \n",
       "380      1.9 -4.828634e-01 -2.611012e-01  -1.247106e-01 -7.390998e-01   \n",
       "2375     2.8  2.080933e-01  6.948125e-01   8.138861e-01 -4.353648e-01   \n",
       "2958     0.9 -7.396378e-01 -3.843663e-01  -2.670387e-01 -8.596295e-01   \n",
       "2066     2.9 -2.611037e-01  3.813961e-01   5.311531e-01  4.932953e-15   \n",
       "4662     0.8 -9.543946e-01 -8.147030e-01  -8.334664e-01 -8.644507e-01   \n",
       "...      ...           ...           ...            ...           ...   \n",
       "470      4.0  2.198095e+00  1.855505e+00   1.731326e+00 -5.931198e-02   \n",
       "8463     1.5 -8.388461e-01 -8.610883e-01  -9.036688e-01 -1.407901e-01   \n",
       "5623     1.5 -6.579369e-01 -6.303465e-01  -5.747753e-01 -2.762655e-01   \n",
       "8525     0.7 -1.669862e+00 -1.223874e+00  -1.581651e+00 -7.530812e-01   \n",
       "2496     3.6  3.878354e-01  1.364906e+00   1.363965e+00 -1.846629e-01   \n",
       "8627     1.1 -6.427638e-01 -9.403281e-01  -1.029649e+00 -5.824111e-01   \n",
       "3617     1.3 -4.945350e-01 -7.647422e-01  -7.603790e-01 -9.801593e-01   \n",
       "3879     1.0 -4.711918e-01 -5.565401e-01  -4.786077e-01 -1.086225e+00   \n",
       "2228     1.9 -4.015515e-01  2.954747e-01   4.500517e-01 -7.101726e-01   \n",
       "7434     3.1  5.955892e-01  6.074100e-01   7.369519e-01  1.606891e+00   \n",
       "1464     3.6  7.193078e-01  1.612389e+00   1.552454e+00 -3.292986e-01   \n",
       "3028     1.9 -6.672741e-01  1.251809e-01   2.840021e-01 -5.896429e-01   \n",
       "201      0.7 -7.092918e-01 -1.070797e+00  -1.258528e+00  4.932953e-15   \n",
       "1763     0.3 -1.160981e+00 -1.131178e+00  -1.376814e+00 -1.105510e+00   \n",
       "3059     0.6 -1.371070e+00 -9.490695e-01  -1.044074e+00 -9.656957e-01   \n",
       "7984     1.3 -6.030805e-01 -8.282085e-01  -8.536616e-01 -2.849437e-01   \n",
       "6390     2.2 -1.735669e-01 -3.050841e-01  -1.747178e-01  2.878137e-01   \n",
       "4045     1.9 -2.653807e-14  7.082285e-15  -3.498560e-15 -6.523183e-01   \n",
       "7139     1.1 -8.878667e-01 -1.045914e+00  -1.212367e+00 -6.446044e-01   \n",
       "7199     3.8 -2.653807e-14  7.082285e-15  -3.498560e-15  1.327744e+00   \n",
       "7005     2.0  3.423163e-01 -3.193054e-01  -1.910663e-01  1.913899e-01   \n",
       "5681     5.8  2.135069e+00  3.099936e+00   2.569908e+00  2.833402e+00   \n",
       "8121     2.5  3.388148e-01 -6.070351e-01  -5.440017e-01  4.932953e-15   \n",
       "7960     1.3 -6.859486e-01 -7.398089e-01  -7.247969e-01  2.188707e-01   \n",
       "396      0.9 -8.306760e-01 -1.083466e+00  -1.282570e+00 -9.753381e-01   \n",
       "6025     3.1 -5.568412e-02  5.804200e-01   7.129100e-01  8.229658e-01   \n",
       "4837     2.4 -1.280478e-01  7.113754e-01   8.283112e-01  5.385156e-01   \n",
       "8336     0.8 -9.485589e-01 -1.254656e+00  -1.658585e+00 -9.184480e-01   \n",
       "8179     1.1 -6.649398e-01 -4.564141e-01  -3.535897e-01 -4.536853e-01   \n",
       "6969     0.6 -9.205471e-01 -1.218256e+00  -1.568188e+00  4.932953e-15   \n",
       "\n",
       "      PT08.S3(NOx)       NO2(GT)  PT08.S4(NO2)   PT08.S5(O3)             T  \\\n",
       "19    1.325301e+00 -6.563652e-02  2.687408e-01 -6.222881e-01 -1.084921e+00   \n",
       "1377  1.581584e+00  1.445833e-14 -1.793733e-01 -1.186147e+00 -4.343811e-01   \n",
       "5508 -3.789832e-01 -1.295012e+00 -5.875533e-02 -2.264543e-01 -2.348824e-01   \n",
       "2582 -3.858831e-01 -1.292249e-01  9.588220e-01  4.569726e-01  4.937217e-01   \n",
       "3588  5.692651e-01 -1.506974e+00  2.723959e-01 -6.845895e-01  5.660039e-01   \n",
       "4418 -1.032948e-02  9.305819e-01  9.548951e-02  2.102844e-01  1.158718e+00   \n",
       "4334 -1.172476e+00 -8.922858e-01  1.498313e+00  1.107046e+00  9.360885e-01   \n",
       "7177  1.792987e-15  1.596141e+00 -1.329714e-14 -1.602583e-14 -5.341394e-15   \n",
       "8961 -7.144319e-02 -4.514062e-01 -9.820313e-01 -8.482092e-01 -6.252060e-01   \n",
       "7746  7.200780e-01 -2.352056e-01 -1.729132e+00 -1.153423e+00 -1.281528e+00   \n",
       "1242  2.932677e-01 -6.167361e-01  5.472587e-01 -3.913326e-01  9.621102e-01   \n",
       "6694 -1.443545e+00  1.502878e+00  9.727113e-01  2.303987e+00 -1.018833e-01   \n",
       "3776  7.959773e-01 -1.740131e+00  8.233118e-02 -1.140207e+00  8.175458e-01   \n",
       "5759 -1.872326e+00  1.375701e+00  3.034914e+00  2.814984e+00  6.209383e-01   \n",
       "7393 -1.597315e+00  1.411734e+00  1.336027e+00  1.746422e+00 -4.112508e-01   \n",
       "9007 -4.331969e-01 -2.436841e-01 -6.676935e-01 -3.277727e-01 -5.008807e-01   \n",
       "3100 -3.149123e-01 -6.563652e-02  4.865842e-01  4.037165e-02  1.187630e+00   \n",
       "235  -6.848607e-02 -2.140095e-01  8.484382e-01  8.225997e-01 -6.140524e-02   \n",
       "1284 -4.285774e-02 -7.439129e-01  7.073517e-01  2.014741e-01 -2.001869e-01   \n",
       "2829 -1.453711e-01  7.610128e-01  4.639227e-01 -3.252554e-01  2.604361e+00   \n",
       "7442 -1.543101e+00  1.549509e+00  7.753364e-01  1.886757e+00 -1.082029e+00   \n",
       "6925 -6.332951e-01  4.854630e-01 -9.374392e-01  1.550078e+00 -1.428984e+00   \n",
       "4600  4.844945e-01 -6.803245e-01 -3.540867e-01 -8.016405e-01  8.927193e-01   \n",
       "6097 -1.624914e+00  1.545270e+00  1.738818e+00  2.105756e+00 -1.683828e-01   \n",
       "796   1.753097e+00 -9.982665e-01 -6.157912e-01 -1.441016e+00 -8.594002e-01   \n",
       "380   7.447206e-01 -6.379322e-01 -1.589048e-01 -7.758389e-01 -1.539264e-01   \n",
       "2375 -3.474406e-01  1.887171e-01  1.435446e+00 -1.175843e-01  1.586628e+00   \n",
       "2958  4.289860e-02 -7.015206e-01  3.074848e-01 -5.354438e-01  4.561350e-01   \n",
       "2066  1.779402e-01  1.445833e-14  9.485877e-01 -1.641530e-01  7.799591e-01   \n",
       "4662  5.495510e-01 -1.125443e+00 -3.920996e-01 -8.167439e-01  6.729814e-01   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "470  -7.249656e-01  3.158939e-01  1.467611e+00  1.582802e+00 -5.037720e-01   \n",
       "8463  2.853820e-01  3.858412e-01 -1.514944e+00 -8.570195e-01 -1.267072e+00   \n",
       "5623  2.712732e-02 -9.134820e-01 -5.729330e-02 -5.574696e-01  2.306147e-01   \n",
       "8525  1.807311e+00 -7.735875e-01 -2.408248e+00 -1.770773e+00 -1.926285e+00   \n",
       "2496 -6.806089e-01  5.066592e-01  1.671565e+00  3.833437e-01  1.618432e+00   \n",
       "8627  2.459538e-01 -1.080288e-01 -1.452076e+00 -5.883056e-01 -1.564874e+00   \n",
       "3617  8.824103e-02 -1.083051e+00  5.962370e-01 -1.014346e+00  1.147152e+00   \n",
       "3879 -9.312870e-02 -1.612954e+00  4.880463e-01 -8.469506e-01  1.534585e+00   \n",
       "2228  4.421287e-02 -1.080288e-01  7.139309e-01 -5.853688e-01  2.272827e+00   \n",
       "7434 -1.021663e+00  1.032323e+00 -1.676770e-01  9.736333e-01 -8.622915e-01   \n",
       "1464 -6.914517e-01  1.887171e-01  1.507817e+00  3.776800e-01  3.867442e-01   \n",
       "3028 -1.542424e-01  1.675210e-01  3.133329e-01  6.869045e-02  1.002588e+00   \n",
       "201   2.189764e+00  1.445833e-14 -4.213404e-01 -1.550515e+00 -5.962931e-01   \n",
       "1763  1.658469e+00 -1.655347e+00 -2.086141e-01 -1.357947e+00 -3.579463e-03   \n",
       "3059  8.748337e-01 -1.125443e+00 -1.939937e-01 -9.092519e-01  3.000056e-01   \n",
       "7984  2.558109e-01  4.579080e-01 -1.569039e+00 -3.346950e-01 -1.570657e+00   \n",
       "6390  3.157727e+00 -2.775979e-01 -3.365422e-01 -2.214199e-01 -6.974882e-01   \n",
       "4045  1.792987e-15 -6.803245e-01 -1.329714e-14 -1.602583e-14 -5.341394e-15   \n",
       "7139  6.205218e-01 -8.477740e-01 -1.468889e+00 -4.316083e-01 -1.689199e+00   \n",
       "7199  1.792987e-15  1.458366e+00 -1.329714e-14 -1.602583e-14 -5.341394e-15   \n",
       "7005 -5.169819e-01  4.034416e-02 -3.299631e-01 -3.026004e-01 -6.107496e-01   \n",
       "5681 -1.579572e+00  7.610128e-01  2.119679e+00  2.260565e+00  5.081782e-01   \n",
       "8121 -5.564101e-01  1.445833e-14 -1.153090e+00  1.059848e+00 -1.472353e+00   \n",
       "7960  1.996257e-01  1.801743e+00 -1.623865e+00 -2.667299e-01 -1.174550e+00   \n",
       "396   2.156250e+00 -1.189032e+00 -5.704681e-01 -8.287007e-01 -1.313332e+00   \n",
       "6025 -5.633100e-01  1.121347e+00 -4.732426e-01  5.903856e-01 -4.777504e-01   \n",
       "4837 -4.686823e-01  1.039326e-01  1.700534e-01  2.725858e-01 -4.864243e-01   \n",
       "8336  1.196174e+00 -1.197510e+00 -1.489358e+00 -1.616592e+00 -1.382723e+00   \n",
       "8179 -3.089981e-01  1.124110e-01 -1.329265e+00 -8.891141e-01 -6.599015e-01   \n",
       "6969  1.248416e+00  1.445833e-14 -1.112884e+00 -1.283689e+00 -6.917056e-01   \n",
       "\n",
       "                RH            AH  \n",
       "19    1.599036e+00 -3.810828e-01  \n",
       "1377  1.084436e+00  2.067628e-01  \n",
       "5508  1.631382e+00  9.363896e-01  \n",
       "2582 -5.813948e-01  8.791423e-02  \n",
       "3588  8.330178e-01  1.834906e+00  \n",
       "4418 -1.128340e+00  2.774689e-01  \n",
       "4334 -4.328962e-01  9.609484e-01  \n",
       "7177 -1.295427e-14  1.969678e-15  \n",
       "8961  9.756353e-01 -1.324526e-01  \n",
       "7746 -5.299350e-01 -1.508633e+00  \n",
       "1242 -1.019539e+00  1.697206e-01  \n",
       "6694 -5.209279e-02 -1.827517e-01  \n",
       "3776  3.639974e-01  1.814177e+00  \n",
       "5759  2.904833e-01  1.310167e+00  \n",
       "7393  5.022040e-01 -1.606924e-01  \n",
       "9007  1.007982e+00  5.862152e-02  \n",
       "3100 -1.270958e+00  9.005318e-02  \n",
       "235  -8.149841e-02 -1.559935e-01  \n",
       "1284  9.756354e-01  4.935452e-01  \n",
       "2829 -2.078143e+00  7.697563e-02  \n",
       "7442  1.516700e+00 -4.165848e-01  \n",
       "6925  6.992220e-01 -1.114386e+00  \n",
       "4600 -8.504568e-01  3.098762e-01  \n",
       "6097  7.844985e-01  3.950262e-01  \n",
       "796   5.139663e-01 -6.735410e-01  \n",
       "380  -1.084232e+00 -1.067955e+00  \n",
       "2375 -1.115108e+00  9.612742e-01  \n",
       "2958 -3.049816e-01  3.415314e-01  \n",
       "2066 -8.239917e-01  1.864843e-01  \n",
       "4662 -2.696947e-01  7.246114e-01  \n",
       "...            ...           ...  \n",
       "470  -8.048779e-01 -1.135617e+00  \n",
       "8463  1.406991e-02 -1.268429e+00  \n",
       "5623  1.141777e+00  1.436154e+00  \n",
       "8525 -8.813327e-01 -1.927164e+00  \n",
       "2496 -1.373878e+00  5.035284e-01  \n",
       "8627  7.800877e-01 -1.192485e+00  \n",
       "3617  1.860931e-01  2.321216e+00  \n",
       "3879 -3.726146e-01  2.284224e+00  \n",
       "2228 -1.919353e+00  1.365696e-01  \n",
       "7434  8.447801e-01 -4.988233e-01  \n",
       "1464 -6.740227e-01 -1.516156e-01  \n",
       "3028 -1.288601e+00 -1.667946e-01  \n",
       "201   1.074144e+00 -3.245601e-02  \n",
       "1763  4.007545e-01  3.341430e-01  \n",
       "3059 -1.447207e-01  2.796915e-01  \n",
       "7984 -3.726146e-01 -1.608166e+00  \n",
       "6390  1.869568e+00  3.004166e-01  \n",
       "4045 -1.295427e-14  1.969678e-15  \n",
       "7139  1.172653e+00 -1.155438e+00  \n",
       "7199 -1.295427e-14  1.969678e-15  \n",
       "7005  1.374082e+00  1.332570e-01  \n",
       "5681  4.345711e-01  1.255877e+00  \n",
       "8121  1.000630e+00 -1.035455e+00  \n",
       "7960 -5.887463e-01 -1.471275e+00  \n",
       "396   1.021214e+00 -8.835309e-01  \n",
       "6025 -8.975058e-01 -1.177419e+00  \n",
       "4837  5.242584e-01 -2.414014e-01  \n",
       "8336  1.238816e+00 -8.612219e-01  \n",
       "8179 -6.210925e-01 -1.139101e+00  \n",
       "6969  1.462299e+00  6.869986e-02  \n",
       "\n",
       "[5381 rows x 12 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation stages\n",
    "\n",
    "We have now curated our training data by removing data observations and features with a large amount of missing values. We have also normalised the feature vectors. We are now in a good position to work on developing the prediction model and validating it. We will use both the closed form expression for $\\mathbf{w}$ and gradient descent for iterative optimisation. \n",
    "\n",
    "We first organise the dataframe into the vector of targets $\\mathbf{y}$ and the design matrix $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here to get y and X\n",
    "y = normalised_data.iloc[:,0] # the target y for training data\n",
    "X = normalised_data.iloc[:,1:normalised_data.shape[1]]\n",
    "\n",
    "# add a column of vector to design matrix,each line of value for this vector is 1\n",
    "X = np.hstack((np.ones(X.shape[0]).reshape(X.shape[0],1), X))  # the design matrix for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.80684454, -0.4190658 , ..., -1.08492054,\n",
       "         1.59903562, -0.3810828 ],\n",
       "       [ 1.        , -1.34072344, -1.082963  , ..., -0.4343811 ,\n",
       "         1.08443634,  0.20676276],\n",
       "       [ 1.        , -0.61591925, -0.23883781, ..., -0.23488236,\n",
       "         1.63138181,  0.93638955],\n",
       "       ...,\n",
       "       [ 1.        , -0.94855885, -1.25465644, ..., -1.38272299,\n",
       "         1.23881616, -0.86122189],\n",
       "       [ 1.        , -0.66493982, -0.45641411, ..., -0.65990145,\n",
       "        -0.62109252, -1.13910134],\n",
       "       [ 1.        , -0.9205471 , -1.21825612, ..., -0.69170561,\n",
       "         1.46229921,  0.06869986]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: training with closed form expression for $\\mathbf{w}$ (3 marks)\n",
    "\n",
    "To find the optimal value of $\\mathbf{w}$ using the closed form expression that you derived before, we need to know the value of the regularisation parameter $\\alpha$ in advance. We will determine the value by using part of the training data for finding the parameters $\\mathbf{w}$ and another part of the training data to choose the best $\\alpha$ from a set of predefined values.\n",
    "\n",
    "* Use `np.logspace(start, stop, num)` to create a set of values for $\\alpha$ in log scale. Use the following parameters `start=-3`, `stop=2` and `num=20`. \n",
    "\n",
    "* Randomly split the training data into what is properly called the training set and the validation set. As before, make sure that you use a random seed that corresponds to the last five digits of your student UCard. Use 70% of the data for the training set and 30% of the data for the validation set.\n",
    "\n",
    "* For each value that you have for $\\alpha$ from the previous step, use the training set to compute $\\mathbf{w}$ and then measure the mean-squared error (MSE) over the validation data. After this, you will have `num=20` MSE values. Choose the value of $\\alpha$ that leads to the lower MSE and save it. You will use it at the test stage.\n",
    "\n",
    "* What was the best value of $\\alpha$? Is there any explanation for that?\n",
    "\n",
    "#### Question 6 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = -3\n",
    "stop = 2\n",
    "num = 20\n",
    "a_range = np.logspace(start, stop, num) \n",
    "\n",
    "MyStudentID = 14433\n",
    "training_set_number = round(0.7 * normalised_data.shape[0])      # the number of training set\n",
    "validation_set_number = normalised_data.shape[0] - training_set_number     # the number of validation set\n",
    "\n",
    "\n",
    "# generate a random sequence for the data according to UCard number\n",
    "np.random.seed(MyStudentID)\n",
    "rearranged_normalised_data = normalised_data.reindex(np.random.permutation(normalised_data.index)) \n",
    "\n",
    "\n",
    "training_set = rearranged_normalised_data[0:training_set_number]   # training set               \n",
    "validation_set = rearranged_normalised_data[training_set_number:normalised_data.shape[0]] #validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = training_set.iloc[:,0]# target y1 for training set\n",
    "X1 = training_set.iloc[:,1:training_set.shape[1]]\n",
    "X1 = np.hstack((np.ones(X1.shape[0]).reshape(X1.shape[0],1), X1)) # add a column of 1 into design matrix X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_values = [] #initialise a list to store w\n",
    "n = training_set.shape[0]\n",
    "for a in a_range: #use every a to compute w, 20 a's for every 20 b's\n",
    "    w = np.dot(np.linalg.inv(np.dot(2/n * X1.T,X1) + a), 2/n * (X1.T).dot(y1)) #as mentioned in lab3, usually we don't directly compute the inverse of a matrix,so we should call the function np.linalg.solve()\n",
    "    w_values.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = validation_set.iloc[:,0] # target y2 for validation set\n",
    "X2 = validation_set.iloc[:,1:validation_set.shape[1]]\n",
    "X2 = np.hstack((np.ones(X2.shape[0]).reshape(X2.shape[0],1), X2)) #design matrix for validation set\n",
    "\n",
    "#store all the values into array\n",
    "MSE_values = []\n",
    "for w in w_values:\n",
    "    MSE = ((y2 - X2.dot(w)).T.dot(y2 - X2.dot(w)))/ validation_set.shape[0]\n",
    "    MSE_values.append(MSE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25349266800762776\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "temp = 1 # initialise a temp to compare\n",
    "count = 0 # index of the minimum MSE we want\n",
    "\n",
    "#find the minimum MSE and the index of it\n",
    "for i in range(len(MSE_values)):\n",
    "    if MSE_values[i]<temp:\n",
    "        temp = MSE_values[i]\n",
    "        count = i \n",
    "\n",
    "\n",
    "print(temp)\n",
    "print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_range[count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of miminum MSE respond to the index of $\\mathbf{a}$ in this case,MSE_value[0] is the minimum MSE ,and a_range[0] is the respoding a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: validation with the closed form expression for $\\mathbf{w}$ (2 marks)\n",
    "\n",
    "We are going to deal now with the test data to perform the validation of the model. Remember that the test data might also contain missing values in the target variable and in the input features.\n",
    "\n",
    "* Remove the rows of the test data for which the labels have missing values. \n",
    "* If you remove any feature at the training stage, you also need to remove the same features from the test stage.\n",
    "* Replace the missing values on each feature variables with the mean value you computed in the training data.\n",
    "* Normalise the test data using the means and standard deviations computed from the training data\n",
    "* Compute again $\\mathbf{w}$ for the value of $\\alpha$ that best performed on the validation set using ALL the training data (not all the training set).\n",
    "* Report the MSE on the preprocessed test data and an histogram with the absolute error.\n",
    "* Does the regularisation have any effect on the model? Explain your answer.\n",
    "\n",
    "#### Question 7 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test_data = test_data[test_data['CO(GT)']!= -200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test_data.drop(preprocessed_test_data.columns[2],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shawn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for j in range(preprocessed_test_data.shape[1]):\n",
    "    for i in range(preprocessed_test_data.shape[0]):\n",
    "        if preprocessed_test_data.iloc[i,j] == -200:\n",
    "            preprocessed_test_data.iloc[i,j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test_data.fillna(selected_data.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X = preprocessed_test_data.iloc[:,1:12] # We should only normalise the input features X, target y (CO(GT)) stay the same\n",
    "normalised_X = (input_X - input_features.mean())/input_features.std() # use the mean and standard deviation from training data\n",
    "normalised_X.insert(0,'CO(GT)',preprocessed_test_data.iloc[:,0]) #put y back to data\n",
    "preprocessed_test_data = normalised_X # Rename it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1.961162</td>\n",
       "      <td>2.696449</td>\n",
       "      <td>2.310255</td>\n",
       "      <td>-0.146093</td>\n",
       "      <td>-0.998006</td>\n",
       "      <td>0.527855</td>\n",
       "      <td>2.305358</td>\n",
       "      <td>1.320381</td>\n",
       "      <td>0.782850</td>\n",
       "      <td>-1.038653</td>\n",
       "      <td>-0.089153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1.684546</td>\n",
       "      <td>1.479952</td>\n",
       "      <td>1.452440</td>\n",
       "      <td>1.199019</td>\n",
       "      <td>-1.345960</td>\n",
       "      <td>0.400678</td>\n",
       "      <td>1.455914</td>\n",
       "      <td>1.417924</td>\n",
       "      <td>0.672982</td>\n",
       "      <td>0.408106</td>\n",
       "      <td>1.559056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>4.3</td>\n",
       "      <td>0.934065</td>\n",
       "      <td>0.898336</td>\n",
       "      <td>0.987950</td>\n",
       "      <td>2.090939</td>\n",
       "      <td>-1.234575</td>\n",
       "      <td>0.621118</td>\n",
       "      <td>0.071366</td>\n",
       "      <td>1.258709</td>\n",
       "      <td>-1.249724</td>\n",
       "      <td>1.524051</td>\n",
       "      <td>-0.606037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.602167</td>\n",
       "      <td>-1.114014</td>\n",
       "      <td>-1.342193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.945796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.590969</td>\n",
       "      <td>-1.585756</td>\n",
       "      <td>-0.454620</td>\n",
       "      <td>-0.731364</td>\n",
       "      <td>-1.048243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.085116</td>\n",
       "      <td>-0.950230</td>\n",
       "      <td>-1.045997</td>\n",
       "      <td>-1.119974</td>\n",
       "      <td>1.116331</td>\n",
       "      <td>-1.676543</td>\n",
       "      <td>0.160550</td>\n",
       "      <td>-1.239638</td>\n",
       "      <td>0.982349</td>\n",
       "      <td>-0.329976</td>\n",
       "      <td>1.191774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.661438</td>\n",
       "      <td>-0.574510</td>\n",
       "      <td>-0.501688</td>\n",
       "      <td>-0.951232</td>\n",
       "      <td>0.454923</td>\n",
       "      <td>-1.061855</td>\n",
       "      <td>0.351346</td>\n",
       "      <td>-1.161604</td>\n",
       "      <td>2.040560</td>\n",
       "      <td>-1.503263</td>\n",
       "      <td>0.870494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8570</th>\n",
       "      <td>5.3</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>1.198490</td>\n",
       "      <td>1.233177</td>\n",
       "      <td>2.399977</td>\n",
       "      <td>-1.086719</td>\n",
       "      <td>2.560565</td>\n",
       "      <td>-0.475436</td>\n",
       "      <td>2.048489</td>\n",
       "      <td>-1.333571</td>\n",
       "      <td>-0.894565</td>\n",
       "      <td>-1.687886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.273028</td>\n",
       "      <td>-1.012695</td>\n",
       "      <td>-1.152743</td>\n",
       "      <td>-0.628212</td>\n",
       "      <td>0.858077</td>\n",
       "      <td>-0.765109</td>\n",
       "      <td>-1.683078</td>\n",
       "      <td>-0.622917</td>\n",
       "      <td>-1.668960</td>\n",
       "      <td>0.252256</td>\n",
       "      <td>-1.448804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.959063</td>\n",
       "      <td>-1.086476</td>\n",
       "      <td>-1.288340</td>\n",
       "      <td>-0.513468</td>\n",
       "      <td>0.890605</td>\n",
       "      <td>0.099693</td>\n",
       "      <td>-1.938934</td>\n",
       "      <td>-1.055251</td>\n",
       "      <td>-1.455005</td>\n",
       "      <td>-0.666671</td>\n",
       "      <td>-1.657050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>2.8</td>\n",
       "      <td>0.422850</td>\n",
       "      <td>0.204122</td>\n",
       "      <td>0.361898</td>\n",
       "      <td>0.827787</td>\n",
       "      <td>-0.826493</td>\n",
       "      <td>1.842016</td>\n",
       "      <td>0.073559</td>\n",
       "      <td>0.430542</td>\n",
       "      <td>-0.012253</td>\n",
       "      <td>0.174331</td>\n",
       "      <td>0.126604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>2.8</td>\n",
       "      <td>0.646944</td>\n",
       "      <td>0.668427</td>\n",
       "      <td>0.790806</td>\n",
       "      <td>-0.348583</td>\n",
       "      <td>-0.570210</td>\n",
       "      <td>0.697424</td>\n",
       "      <td>1.491734</td>\n",
       "      <td>0.161828</td>\n",
       "      <td>2.066581</td>\n",
       "      <td>-1.282720</td>\n",
       "      <td>1.454522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.017421</td>\n",
       "      <td>-0.490051</td>\n",
       "      <td>-0.394942</td>\n",
       "      <td>-1.038014</td>\n",
       "      <td>-0.030044</td>\n",
       "      <td>-1.167836</td>\n",
       "      <td>-0.216655</td>\n",
       "      <td>-0.651866</td>\n",
       "      <td>1.025718</td>\n",
       "      <td>-1.097464</td>\n",
       "      <td>0.142521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>4.6</td>\n",
       "      <td>0.758991</td>\n",
       "      <td>1.316737</td>\n",
       "      <td>1.326460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.010820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469040</td>\n",
       "      <td>0.587868</td>\n",
       "      <td>-1.047334</td>\n",
       "      <td>1.543165</td>\n",
       "      <td>-0.361825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>2.3</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.377280</td>\n",
       "      <td>0.527306</td>\n",
       "      <td>-0.570358</td>\n",
       "      <td>0.219340</td>\n",
       "      <td>0.082736</td>\n",
       "      <td>0.406903</td>\n",
       "      <td>-0.303859</td>\n",
       "      <td>1.199196</td>\n",
       "      <td>-1.606182</td>\n",
       "      <td>-0.434078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8265</th>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.848183</td>\n",
       "      <td>-1.151576</td>\n",
       "      <td>-1.419128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.701353</td>\n",
       "      <td>-1.408292</td>\n",
       "      <td>-1.394288</td>\n",
       "      <td>0.214028</td>\n",
       "      <td>-1.277787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.695286</td>\n",
       "      <td>-0.903471</td>\n",
       "      <td>-0.970025</td>\n",
       "      <td>-0.941590</td>\n",
       "      <td>0.947776</td>\n",
       "      <td>-1.231424</td>\n",
       "      <td>0.207335</td>\n",
       "      <td>-0.829330</td>\n",
       "      <td>-0.223317</td>\n",
       "      <td>0.883008</td>\n",
       "      <td>0.385109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.927550</td>\n",
       "      <td>-1.023004</td>\n",
       "      <td>-1.171015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.791999</td>\n",
       "      <td>-0.313928</td>\n",
       "      <td>-1.738351</td>\n",
       "      <td>-0.024157</td>\n",
       "      <td>-1.580957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>3.6</td>\n",
       "      <td>0.930563</td>\n",
       "      <td>0.770339</td>\n",
       "      <td>0.879280</td>\n",
       "      <td>0.880820</td>\n",
       "      <td>-0.454882</td>\n",
       "      <td>0.549051</td>\n",
       "      <td>0.419331</td>\n",
       "      <td>0.541300</td>\n",
       "      <td>-0.457511</td>\n",
       "      <td>1.272633</td>\n",
       "      <td>0.299107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.269527</td>\n",
       "      <td>-0.862337</td>\n",
       "      <td>-0.905592</td>\n",
       "      <td>-0.830702</td>\n",
       "      <td>1.840825</td>\n",
       "      <td>-0.743913</td>\n",
       "      <td>-0.259785</td>\n",
       "      <td>-1.227052</td>\n",
       "      <td>0.080268</td>\n",
       "      <td>-0.312333</td>\n",
       "      <td>-0.178406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8257</th>\n",
       "      <td>2.8</td>\n",
       "      <td>0.278123</td>\n",
       "      <td>0.104989</td>\n",
       "      <td>0.263807</td>\n",
       "      <td>0.281546</td>\n",
       "      <td>-0.799879</td>\n",
       "      <td>1.755112</td>\n",
       "      <td>-0.761264</td>\n",
       "      <td>0.293982</td>\n",
       "      <td>-1.165877</td>\n",
       "      <td>-0.082969</td>\n",
       "      <td>-1.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>3.4</td>\n",
       "      <td>1.419602</td>\n",
       "      <td>1.361188</td>\n",
       "      <td>1.361080</td>\n",
       "      <td>-0.059312</td>\n",
       "      <td>-0.753551</td>\n",
       "      <td>0.506659</td>\n",
       "      <td>1.518782</td>\n",
       "      <td>1.777258</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>-0.543167</td>\n",
       "      <td>-0.065312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2.3</td>\n",
       "      <td>0.104216</td>\n",
       "      <td>0.290773</td>\n",
       "      <td>0.445564</td>\n",
       "      <td>-0.570358</td>\n",
       "      <td>-0.093129</td>\n",
       "      <td>-0.086833</td>\n",
       "      <td>0.541411</td>\n",
       "      <td>0.682264</td>\n",
       "      <td>0.360723</td>\n",
       "      <td>-0.869570</td>\n",
       "      <td>-0.388209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.219339</td>\n",
       "      <td>-0.850428</td>\n",
       "      <td>-0.887320</td>\n",
       "      <td>-1.081404</td>\n",
       "      <td>1.116331</td>\n",
       "      <td>-1.443385</td>\n",
       "      <td>-0.403796</td>\n",
       "      <td>-1.456119</td>\n",
       "      <td>2.506057</td>\n",
       "      <td>-2.044327</td>\n",
       "      <td>0.063961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7287</th>\n",
       "      <td>3.4</td>\n",
       "      <td>0.990088</td>\n",
       "      <td>0.605245</td>\n",
       "      <td>0.735029</td>\n",
       "      <td>1.574589</td>\n",
       "      <td>-1.119248</td>\n",
       "      <td>0.222631</td>\n",
       "      <td>-0.123816</td>\n",
       "      <td>1.062365</td>\n",
       "      <td>-1.255506</td>\n",
       "      <td>1.687253</td>\n",
       "      <td>-0.542393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1.111472</td>\n",
       "      <td>0.990823</td>\n",
       "      <td>1.064884</td>\n",
       "      <td>0.789217</td>\n",
       "      <td>-0.701309</td>\n",
       "      <td>0.146325</td>\n",
       "      <td>0.596968</td>\n",
       "      <td>0.508576</td>\n",
       "      <td>-0.544250</td>\n",
       "      <td>1.572570</td>\n",
       "      <td>0.360125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.350061</td>\n",
       "      <td>-0.935638</td>\n",
       "      <td>-1.021955</td>\n",
       "      <td>-1.071762</td>\n",
       "      <td>1.153788</td>\n",
       "      <td>-1.549366</td>\n",
       "      <td>-0.511256</td>\n",
       "      <td>-1.644282</td>\n",
       "      <td>2.358601</td>\n",
       "      <td>-1.804671</td>\n",
       "      <td>0.568795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.676611</td>\n",
       "      <td>-0.785985</td>\n",
       "      <td>-0.791153</td>\n",
       "      <td>-0.033278</td>\n",
       "      <td>0.234125</td>\n",
       "      <td>1.225208</td>\n",
       "      <td>-1.769338</td>\n",
       "      <td>-0.685219</td>\n",
       "      <td>-0.804466</td>\n",
       "      <td>-1.415046</td>\n",
       "      <td>-1.686420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755</th>\n",
       "      <td>1.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.065637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>2.3</td>\n",
       "      <td>0.135730</td>\n",
       "      <td>0.471905</td>\n",
       "      <td>0.614819</td>\n",
       "      <td>-0.560716</td>\n",
       "      <td>-0.175928</td>\n",
       "      <td>0.379482</td>\n",
       "      <td>1.005607</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>2.630382</td>\n",
       "      <td>-1.884066</td>\n",
       "      <td>0.729414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.128301</td>\n",
       "      <td>-0.737090</td>\n",
       "      <td>-0.720950</td>\n",
       "      <td>-0.941590</td>\n",
       "      <td>0.742749</td>\n",
       "      <td>-1.167836</td>\n",
       "      <td>-0.289026</td>\n",
       "      <td>-1.323965</td>\n",
       "      <td>2.549426</td>\n",
       "      <td>-1.994337</td>\n",
       "      <td>0.270403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.487044</td>\n",
       "      <td>-0.055186</td>\n",
       "      <td>0.099360</td>\n",
       "      <td>-0.396795</td>\n",
       "      <td>-0.636252</td>\n",
       "      <td>-1.040659</td>\n",
       "      <td>0.351346</td>\n",
       "      <td>0.158681</td>\n",
       "      <td>0.531308</td>\n",
       "      <td>0.666876</td>\n",
       "      <td>1.567229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2.2</td>\n",
       "      <td>-0.669608</td>\n",
       "      <td>0.287753</td>\n",
       "      <td>0.442679</td>\n",
       "      <td>-0.599285</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>0.188717</td>\n",
       "      <td>0.586003</td>\n",
       "      <td>-0.579495</td>\n",
       "      <td>1.433390</td>\n",
       "      <td>-1.762033</td>\n",
       "      <td>-0.459615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8384</th>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.997579</td>\n",
       "      <td>-1.165562</td>\n",
       "      <td>-1.448940</td>\n",
       "      <td>-0.764652</td>\n",
       "      <td>0.934962</td>\n",
       "      <td>-0.595540</td>\n",
       "      <td>-1.444035</td>\n",
       "      <td>-1.225164</td>\n",
       "      <td>-1.593787</td>\n",
       "      <td>1.735772</td>\n",
       "      <td>-0.878493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.685949</td>\n",
       "      <td>-0.401376</td>\n",
       "      <td>-0.287234</td>\n",
       "      <td>-0.411259</td>\n",
       "      <td>0.563351</td>\n",
       "      <td>-0.425971</td>\n",
       "      <td>0.692731</td>\n",
       "      <td>-0.120102</td>\n",
       "      <td>0.242180</td>\n",
       "      <td>0.599243</td>\n",
       "      <td>0.927092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>2.1</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>-0.394101</td>\n",
       "      <td>-0.278579</td>\n",
       "      <td>0.210675</td>\n",
       "      <td>-0.475582</td>\n",
       "      <td>0.167521</td>\n",
       "      <td>-0.529531</td>\n",
       "      <td>0.026527</td>\n",
       "      <td>-0.613641</td>\n",
       "      <td>0.906532</td>\n",
       "      <td>-0.159776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.321796</td>\n",
       "      <td>-0.071604</td>\n",
       "      <td>0.082050</td>\n",
       "      <td>-0.975338</td>\n",
       "      <td>-0.439111</td>\n",
       "      <td>-1.612954</td>\n",
       "      <td>0.895954</td>\n",
       "      <td>0.055475</td>\n",
       "      <td>1.635780</td>\n",
       "      <td>-0.609330</td>\n",
       "      <td>2.055159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0.7</td>\n",
       "      <td>-1.153978</td>\n",
       "      <td>-0.920856</td>\n",
       "      <td>-0.997913</td>\n",
       "      <td>-0.960874</td>\n",
       "      <td>1.230673</td>\n",
       "      <td>-1.485778</td>\n",
       "      <td>0.033353</td>\n",
       "      <td>-0.704098</td>\n",
       "      <td>-0.526902</td>\n",
       "      <td>1.231465</td>\n",
       "      <td>0.166757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.187084</td>\n",
       "      <td>0.295811</td>\n",
       "      <td>0.450372</td>\n",
       "      <td>-0.584822</td>\n",
       "      <td>-0.061586</td>\n",
       "      <td>0.146325</td>\n",
       "      <td>0.602816</td>\n",
       "      <td>0.372016</td>\n",
       "      <td>0.253745</td>\n",
       "      <td>-0.672552</td>\n",
       "      <td>-0.309608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8044</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.477309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7165</th>\n",
       "      <td>1.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>3.4</td>\n",
       "      <td>0.573413</td>\n",
       "      <td>0.884597</td>\n",
       "      <td>0.976409</td>\n",
       "      <td>1.170091</td>\n",
       "      <td>-0.571196</td>\n",
       "      <td>-0.023244</td>\n",
       "      <td>0.352808</td>\n",
       "      <td>0.665902</td>\n",
       "      <td>-0.593402</td>\n",
       "      <td>0.974165</td>\n",
       "      <td>-0.090922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1.427772</td>\n",
       "      <td>1.186427</td>\n",
       "      <td>1.223560</td>\n",
       "      <td>-0.179842</td>\n",
       "      <td>-0.330684</td>\n",
       "      <td>0.485463</td>\n",
       "      <td>0.930312</td>\n",
       "      <td>1.117744</td>\n",
       "      <td>0.360723</td>\n",
       "      <td>-1.572366</td>\n",
       "      <td>-1.123584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.157480</td>\n",
       "      <td>-0.962912</td>\n",
       "      <td>-1.067154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092565</td>\n",
       "      <td>-0.602780</td>\n",
       "      <td>0.667199</td>\n",
       "      <td>-0.085909</td>\n",
       "      <td>0.940564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.411667</td>\n",
       "      <td>-0.938572</td>\n",
       "      <td>-1.026763</td>\n",
       "      <td>-0.811418</td>\n",
       "      <td>1.460342</td>\n",
       "      <td>-0.807501</td>\n",
       "      <td>-0.385520</td>\n",
       "      <td>-1.281801</td>\n",
       "      <td>-0.856509</td>\n",
       "      <td>0.937408</td>\n",
       "      <td>-0.442320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.069455</td>\n",
       "      <td>1.739486</td>\n",
       "      <td>1.646698</td>\n",
       "      <td>0.022648</td>\n",
       "      <td>-1.022649</td>\n",
       "      <td>1.396897</td>\n",
       "      <td>1.671565</td>\n",
       "      <td>1.180046</td>\n",
       "      <td>2.248732</td>\n",
       "      <td>-1.644410</td>\n",
       "      <td>0.843128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8558</th>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.066189</td>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.248420</td>\n",
       "      <td>0.674955</td>\n",
       "      <td>-0.538667</td>\n",
       "      <td>0.729219</td>\n",
       "      <td>-1.137007</td>\n",
       "      <td>0.521791</td>\n",
       "      <td>-2.264565</td>\n",
       "      <td>0.130222</td>\n",
       "      <td>-1.798263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7801</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.959063</td>\n",
       "      <td>-0.995634</td>\n",
       "      <td>-1.122931</td>\n",
       "      <td>-0.322067</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>0.404918</td>\n",
       "      <td>-1.758373</td>\n",
       "      <td>-1.201879</td>\n",
       "      <td>-1.692091</td>\n",
       "      <td>-0.065325</td>\n",
       "      <td>-1.568697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.8</td>\n",
       "      <td>0.518557</td>\n",
       "      <td>-0.461925</td>\n",
       "      <td>-0.360321</td>\n",
       "      <td>-0.714994</td>\n",
       "      <td>0.678678</td>\n",
       "      <td>-0.574344</td>\n",
       "      <td>0.353539</td>\n",
       "      <td>0.258112</td>\n",
       "      <td>-0.500881</td>\n",
       "      <td>0.712455</td>\n",
       "      <td>-0.135701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.507374</td>\n",
       "      <td>0.028172</td>\n",
       "      <td>0.185911</td>\n",
       "      <td>-0.734279</td>\n",
       "      <td>-0.053700</td>\n",
       "      <td>-0.404775</td>\n",
       "      <td>0.821391</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>0.730807</td>\n",
       "      <td>-0.565222</td>\n",
       "      <td>0.447528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>2.6</td>\n",
       "      <td>0.617765</td>\n",
       "      <td>0.399967</td>\n",
       "      <td>0.548463</td>\n",
       "      <td>-0.526967</td>\n",
       "      <td>-0.364198</td>\n",
       "      <td>-0.065637</td>\n",
       "      <td>1.241726</td>\n",
       "      <td>0.221612</td>\n",
       "      <td>0.832002</td>\n",
       "      <td>-0.213824</td>\n",
       "      <td>1.074357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>3.6</td>\n",
       "      <td>0.527894</td>\n",
       "      <td>1.210577</td>\n",
       "      <td>1.242794</td>\n",
       "      <td>0.292635</td>\n",
       "      <td>-0.767351</td>\n",
       "      <td>0.888190</td>\n",
       "      <td>1.333103</td>\n",
       "      <td>1.075581</td>\n",
       "      <td>0.962110</td>\n",
       "      <td>-1.128340</td>\n",
       "      <td>0.014419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.037688</td>\n",
       "      <td>0.828855</td>\n",
       "      <td>0.929287</td>\n",
       "      <td>1.676316</td>\n",
       "      <td>-0.604710</td>\n",
       "      <td>1.545270</td>\n",
       "      <td>-0.431575</td>\n",
       "      <td>0.547593</td>\n",
       "      <td>-0.116340</td>\n",
       "      <td>-1.369467</td>\n",
       "      <td>-1.269808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.632259</td>\n",
       "      <td>-0.060668</td>\n",
       "      <td>0.093590</td>\n",
       "      <td>-0.758385</td>\n",
       "      <td>0.152312</td>\n",
       "      <td>-0.447167</td>\n",
       "      <td>0.308216</td>\n",
       "      <td>-0.840658</td>\n",
       "      <td>2.147537</td>\n",
       "      <td>-1.956110</td>\n",
       "      <td>-0.109351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6344</th>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.461855</td>\n",
       "      <td>-0.802372</td>\n",
       "      <td>-0.815195</td>\n",
       "      <td>-0.637855</td>\n",
       "      <td>2.692474</td>\n",
       "      <td>-0.849894</td>\n",
       "      <td>-0.459353</td>\n",
       "      <td>-0.707874</td>\n",
       "      <td>-0.515337</td>\n",
       "      <td>2.069526</td>\n",
       "      <td>0.730620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.161895</td>\n",
       "      <td>-0.018398</td>\n",
       "      <td>0.137827</td>\n",
       "      <td>-0.724636</td>\n",
       "      <td>-0.191699</td>\n",
       "      <td>-0.086833</td>\n",
       "      <td>0.736592</td>\n",
       "      <td>-0.305747</td>\n",
       "      <td>1.274369</td>\n",
       "      <td>-0.853397</td>\n",
       "      <td>0.902473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.159073</td>\n",
       "      <td>0.192321</td>\n",
       "      <td>0.350358</td>\n",
       "      <td>-0.642676</td>\n",
       "      <td>-0.318855</td>\n",
       "      <td>-0.277598</td>\n",
       "      <td>0.556762</td>\n",
       "      <td>0.273215</td>\n",
       "      <td>1.306173</td>\n",
       "      <td>-1.307715</td>\n",
       "      <td>0.186058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.225175</td>\n",
       "      <td>-0.978839</td>\n",
       "      <td>-1.094081</td>\n",
       "      <td>-1.086225</td>\n",
       "      <td>0.836391</td>\n",
       "      <td>-1.591758</td>\n",
       "      <td>0.360118</td>\n",
       "      <td>-0.804158</td>\n",
       "      <td>0.829111</td>\n",
       "      <td>0.316948</td>\n",
       "      <td>1.777062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.100289</td>\n",
       "      <td>-0.648357</td>\n",
       "      <td>-0.598817</td>\n",
       "      <td>-0.015921</td>\n",
       "      <td>0.464780</td>\n",
       "      <td>0.358286</td>\n",
       "      <td>-1.444766</td>\n",
       "      <td>-0.307006</td>\n",
       "      <td>-1.674743</td>\n",
       "      <td>0.455155</td>\n",
       "      <td>-1.384391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9030</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.163063</td>\n",
       "      <td>-0.604835</td>\n",
       "      <td>-0.541117</td>\n",
       "      <td>-0.504308</td>\n",
       "      <td>-0.513039</td>\n",
       "      <td>-0.203411</td>\n",
       "      <td>-0.654535</td>\n",
       "      <td>-0.390074</td>\n",
       "      <td>-0.509555</td>\n",
       "      <td>0.965343</td>\n",
       "      <td>0.018429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.382741</td>\n",
       "      <td>-1.189581</td>\n",
       "      <td>-1.501832</td>\n",
       "      <td>-1.201934</td>\n",
       "      <td>1.600313</td>\n",
       "      <td>-2.206446</td>\n",
       "      <td>0.118151</td>\n",
       "      <td>-1.496395</td>\n",
       "      <td>0.892719</td>\n",
       "      <td>0.816845</td>\n",
       "      <td>2.607273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2293 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CO(GT)  PT08.S1(CO)  C6H6(GT)  PT08.S2(NMHC)   NOx(GT)  PT08.S3(NOx)  \\\n",
       "1488     4.6     1.961162  2.696449       2.310255 -0.146093     -0.998006   \n",
       "4914     3.7     1.684546  1.479952       1.452440  1.199019     -1.345960   \n",
       "7431     4.3     0.934065  0.898336       0.987950  2.090939     -1.234575   \n",
       "6585     0.5    -1.602167 -1.114014      -1.342193  0.000000      4.945796   \n",
       "2264     0.6    -1.085116 -0.950230      -1.045997 -1.119974      1.116331   \n",
       "2541     1.3    -0.661438 -0.574510      -0.501688 -0.951232      0.454923   \n",
       "8570     5.3     0.945736  1.198490       1.233177  2.399977     -1.086719   \n",
       "6803     1.0    -1.273028 -1.012695      -1.152743 -0.628212      0.858077   \n",
       "7997     1.0    -0.959063 -1.086476      -1.288340 -0.513468      0.890605   \n",
       "6090     2.8     0.422850  0.204122       0.361898  0.827787     -0.826493   \n",
       "2658     2.8     0.646944  0.668427       0.790806 -0.348583     -0.570210   \n",
       "3988     1.2    -1.017421 -0.490051      -0.394942 -1.038014     -0.030044   \n",
       "5857     4.6     0.758991  1.316737       1.326460  0.000000     -1.010820   \n",
       "1558     2.3     0.001507  0.377280       0.527306 -0.570358      0.219340   \n",
       "8265     0.8    -0.848183 -1.151576      -1.419128  0.000000      0.619536   \n",
       "1283     0.7    -0.695286 -0.903471      -0.970025 -0.941590      0.947776   \n",
       "7977     0.9    -0.927550 -1.023004      -1.171015  0.000000      0.573208   \n",
       "6352     3.6     0.930563  0.770339       0.879280  0.880820     -0.454882   \n",
       "1909     0.5    -1.269527 -0.862337      -0.905592 -0.830702      1.840825   \n",
       "8257     2.8     0.278123  0.104989       0.263807  0.281546     -0.799879   \n",
       "1719     3.4     1.419602  1.361188       1.361080 -0.059312     -0.753551   \n",
       "1564     2.3     0.104216  0.290773       0.445564 -0.570358     -0.093129   \n",
       "2781     0.5    -1.219339 -0.850428      -0.887320 -1.081404      1.116331   \n",
       "7287     3.4     0.990088  0.605245       0.735029  1.574589     -1.119248   \n",
       "6351     3.6     1.111472  0.990823       1.064884  0.789217     -0.701309   \n",
       "3452     0.6    -1.350061 -0.935638      -1.021955 -1.071762      1.153788   \n",
       "7986     1.7    -0.676611 -0.785985      -0.791153 -0.033278      0.234125   \n",
       "6755     1.8     0.000000  0.000000       0.000000  0.552979      0.000000   \n",
       "2205     2.3     0.135730  0.471905       0.614819 -0.560716     -0.175928   \n",
       "3814     1.0    -1.128301 -0.737090      -0.720950 -0.941590      0.742749   \n",
       "...      ...          ...       ...            ...       ...           ...   \n",
       "5094     1.6     0.487044 -0.055186       0.099360 -0.396795     -0.636252   \n",
       "2471     2.2    -0.669608  0.287753       0.442679 -0.599285      0.031070   \n",
       "8384     0.8    -0.997579 -1.165562      -1.448940 -0.764652      0.934962   \n",
       "2077     1.5    -0.685949 -0.401376      -0.287234 -0.411259      0.563351   \n",
       "7011     2.1     0.020181 -0.394101      -0.278579  0.210675     -0.475582   \n",
       "3640     1.4    -0.321796 -0.071604       0.082050 -0.975338     -0.439111   \n",
       "1260     0.7    -1.153978 -0.920856      -0.997913 -0.960874      1.230673   \n",
       "1155     2.5     0.187084  0.295811       0.450372 -0.584822     -0.061586   \n",
       "8044     1.1     0.000000  0.000000       0.000000 -0.477309      0.000000   \n",
       "7165     1.8     0.000000  0.000000       0.000000  0.529837      0.000000   \n",
       "6519     3.4     0.573413  0.884597       0.976409  1.170091     -0.571196   \n",
       "474      3.7     1.427772  1.186427       1.223560 -0.179842     -0.330684   \n",
       "2817     0.6    -1.157480 -0.962912      -1.067154  0.000000      0.731906   \n",
       "791      1.2    -0.411667 -0.938572      -1.026763 -0.811418      1.460342   \n",
       "3217     4.0     1.069455  1.739486       1.646698  0.022648     -1.022649   \n",
       "8558     2.4    -0.066189  0.089681       0.248420  0.674955     -0.538667   \n",
       "7801     1.3    -0.959063 -0.995634      -1.122931 -0.322067      0.611650   \n",
       "104      1.8     0.518557 -0.461925      -0.360321 -0.714994      0.678678   \n",
       "2500     1.7    -0.507374  0.028172       0.185911 -0.734279     -0.053700   \n",
       "2261     2.6     0.617765  0.399967       0.548463 -0.526967     -0.364198   \n",
       "2799     3.6     0.527894  1.210577       1.242794  0.292635     -0.767351   \n",
       "6023     3.5     0.037688  0.828855       0.929287  1.676316     -0.604710   \n",
       "2754     1.5    -0.632259 -0.060668       0.093590 -0.758385      0.152312   \n",
       "6344     1.2    -0.461855 -0.802372      -0.815195 -0.637855      2.692474   \n",
       "2715     1.9    -0.161895 -0.018398       0.137827 -0.724636     -0.191699   \n",
       "3124     1.6     0.159073  0.192321       0.350358 -0.642676     -0.318855   \n",
       "2698     0.6    -1.225175 -0.978839      -1.094081 -1.086225      0.836391   \n",
       "6135     0.5    -1.100289 -0.648357      -0.598817 -0.015921      0.464780   \n",
       "9030     1.3    -0.163063 -0.604835      -0.541117 -0.504308     -0.513039   \n",
       "3730     0.5    -1.382741 -1.189581      -1.501832 -1.201934      1.600313   \n",
       "\n",
       "       NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)         T        RH        AH  \n",
       "1488  0.527855      2.305358     1.320381  0.782850 -1.038653 -0.089153  \n",
       "4914  0.400678      1.455914     1.417924  0.672982  0.408106  1.559056  \n",
       "7431  0.621118      0.071366     1.258709 -1.249724  1.524051 -0.606037  \n",
       "6585  0.000000     -1.590969    -1.585756 -0.454620 -0.731364 -1.048243  \n",
       "2264 -1.676543      0.160550    -1.239638  0.982349 -0.329976  1.191774  \n",
       "2541 -1.061855      0.351346    -1.161604  2.040560 -1.503263  0.870494  \n",
       "8570  2.560565     -0.475436     2.048489 -1.333571 -0.894565 -1.687886  \n",
       "6803 -0.765109     -1.683078    -0.622917 -1.668960  0.252256 -1.448804  \n",
       "7997  0.099693     -1.938934    -1.055251 -1.455005 -0.666671 -1.657050  \n",
       "6090  1.842016      0.073559     0.430542 -0.012253  0.174331  0.126604  \n",
       "2658  0.697424      1.491734     0.161828  2.066581 -1.282720  1.454522  \n",
       "3988 -1.167836     -0.216655    -0.651866  1.025718 -1.097464  0.142521  \n",
       "5857  0.000000      0.469040     0.587868 -1.047334  1.543165 -0.361825  \n",
       "1558  0.082736      0.406903    -0.303859  1.199196 -1.606182 -0.434078  \n",
       "8265  0.000000     -1.701353    -1.408292 -1.394288  0.214028 -1.277787  \n",
       "1283 -1.231424      0.207335    -0.829330 -0.223317  0.883008  0.385109  \n",
       "7977  0.000000     -1.791999    -0.313928 -1.738351 -0.024157 -1.580957  \n",
       "6352  0.549051      0.419331     0.541300 -0.457511  1.272633  0.299107  \n",
       "1909 -0.743913     -0.259785    -1.227052  0.080268 -0.312333 -0.178406  \n",
       "8257  1.755112     -0.761264     0.293982 -1.165877 -0.082969 -1.237600  \n",
       "1719  0.506659      1.518782     1.777258  0.346266 -0.543167 -0.065312  \n",
       "1564 -0.086833      0.541411     0.682264  0.360723 -0.869570 -0.388209  \n",
       "2781 -1.443385     -0.403796    -1.456119  2.506057 -2.044327  0.063961  \n",
       "7287  0.222631     -0.123816     1.062365 -1.255506  1.687253 -0.542393  \n",
       "6351  0.146325      0.596968     0.508576 -0.544250  1.572570  0.360125  \n",
       "3452 -1.549366     -0.511256    -1.644282  2.358601 -1.804671  0.568795  \n",
       "7986  1.225208     -1.769338    -0.685219 -0.804466 -1.415046 -1.686420  \n",
       "6755 -0.065637      0.000000     0.000000  0.000000  0.000000  0.000000  \n",
       "2205  0.379482      1.005607     0.001984  2.630382 -1.884066  0.729414  \n",
       "3814 -1.167836     -0.289026    -1.323965  2.549426 -1.994337  0.270403  \n",
       "...        ...           ...          ...       ...       ...       ...  \n",
       "5094 -1.040659      0.351346     0.158681  0.531308  0.666876  1.567229  \n",
       "2471  0.188717      0.586003    -0.579495  1.433390 -1.762033 -0.459615  \n",
       "8384 -0.595540     -1.444035    -1.225164 -1.593787  1.735772 -0.878493  \n",
       "2077 -0.425971      0.692731    -0.120102  0.242180  0.599243  0.927092  \n",
       "7011  0.167521     -0.529531     0.026527 -0.613641  0.906532 -0.159776  \n",
       "3640 -1.612954      0.895954     0.055475  1.635780 -0.609330  2.055159  \n",
       "1260 -1.485778      0.033353    -0.704098 -0.526902  1.231465  0.166757  \n",
       "1155  0.146325      0.602816     0.372016  0.253745 -0.672552 -0.309608  \n",
       "8044  0.245947      0.000000     0.000000  0.000000  0.000000  0.000000  \n",
       "7165  0.125129      0.000000     0.000000  0.000000  0.000000  0.000000  \n",
       "6519 -0.023244      0.352808     0.665902 -0.593402  0.974165 -0.090922  \n",
       "474   0.485463      0.930312     1.117744  0.360723 -1.572366 -1.123584  \n",
       "2817  0.000000      0.092565    -0.602780  0.667199 -0.085909  0.940564  \n",
       "791  -0.807501     -0.385520    -1.281801 -0.856509  0.937408 -0.442320  \n",
       "3217  1.396897      1.671565     1.180046  2.248732 -1.644410  0.843128  \n",
       "8558  0.729219     -1.137007     0.521791 -2.264565  0.130222 -1.798263  \n",
       "7801  0.404918     -1.758373    -1.201879 -1.692091 -0.065325 -1.568697  \n",
       "104  -0.574344      0.353539     0.258112 -0.500881  0.712455 -0.135701  \n",
       "2500 -0.404775      0.821391    -0.071016  0.730807 -0.565222  0.447528  \n",
       "2261 -0.065637      1.241726     0.221612  0.832002 -0.213824  1.074357  \n",
       "2799  0.888190      1.333103     1.075581  0.962110 -1.128340  0.014419  \n",
       "6023  1.545270     -0.431575     0.547593 -0.116340 -1.369467 -1.269808  \n",
       "2754 -0.447167      0.308216    -0.840658  2.147537 -1.956110 -0.109351  \n",
       "6344 -0.849894     -0.459353    -0.707874 -0.515337  2.069526  0.730620  \n",
       "2715 -0.086833      0.736592    -0.305747  1.274369 -0.853397  0.902473  \n",
       "3124 -0.277598      0.556762     0.273215  1.306173 -1.307715  0.186058  \n",
       "2698 -1.591758      0.360118    -0.804158  0.829111  0.316948  1.777062  \n",
       "6135  0.358286     -1.444766    -0.307006 -1.674743  0.455155 -1.384391  \n",
       "9030 -0.203411     -0.654535    -0.390074 -0.509555  0.965343  0.018429  \n",
       "3730 -2.206446      0.118151    -1.496395  0.892719  0.816845  2.607273  \n",
       "\n",
       "[2293 rows x 12 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a_range[0]\n",
    "# Use the X and y according to Quetion 5\n",
    "n_training = normalised_data.shape[0]\n",
    "w = np.dot(np.linalg.inv(np.dot(2/n_training * X.T,X) + a), 2/n_training * (X.T).dot(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2210297368124787"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = preprocessed_test_data.iloc[:,0]\n",
    "Xt = preprocessed_test_data.iloc[:,1:preprocessed_test_data.shape[1]]\n",
    "Xt = np.hstack((np.ones(Xt.shape[0]).reshape(Xt.shape[0],1), Xt))\n",
    "\n",
    "MSE_t = ((yt - Xt.dot(w)).T.dot(yt - Xt.dot(w)))/ preprocessed_test_data.shape[0]\n",
    "MSE_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1741.,  366.,  113.,   36.,   18.,    9.,    6.,    2.,    0.,\n",
       "           2.]),\n",
       " array([1.21900642e-04, 3.87225723e-01, 7.74329546e-01, 1.16143337e+00,\n",
       "        1.54853719e+00, 1.93564101e+00, 2.32274484e+00, 2.70984866e+00,\n",
       "        3.09695248e+00, 3.48405630e+00, 3.87116013e+00]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "absolute_error = abs(yt - Xt.dot(w)).tolist()\n",
    "\n",
    "%matplotlib inline \n",
    "import pylab as plt # this imports the plotting library in python\n",
    "\n",
    "plt.hist(absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Regularization can reduce the degree of nonlinearity of the model and it also can effectively avoid overfitting problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: training with gradient descent and validation (5 marks)\n",
    "\n",
    "\n",
    "Use gradient descent to iteratively compute the value of $\\mathbf{w}_{\\text{new}}$. Instead of using all the training set to compute the gradient, use a subset of $B$ datapoints in the training set. This is sometimes called minibatch gradient descent where $B$ is the size of the minibacth. When using gradient descent with minibatches, you need to find the best values for three parameters: $\\eta$, the learning rate, $B$, the number of datapoints in the minibatch and $\\alpha$, the regularisation parameter.\n",
    "\n",
    "* As you did on Question 6, create a grid of values for the parameters $\\alpha$ and $\\eta$ using `np.logspace` and a grid of values for $B$ using np.linspace. Because you need to find \n",
    " three parameters, start with `num=5` and see if you can increase it.\n",
    "\n",
    "* Use the same training set and validation set that you used in Question 6.\n",
    "\n",
    "* For each value that you have of $\\alpha$, $\\eta$ and $B$ from the previous step, use the training set to compute $\\mathbf{w}$ using minibatch gradient descent and then measure the MSE over the validation data. For the minibatch gradient descent choose to stop the iterative procedure after $500$ iterations.\n",
    "\n",
    "* Choose the values of $\\alpha$, $\\eta$ and $B$ that lead to the lower MSE and save them. You will use them at the test stage.\n",
    "\n",
    "*3 marks of out of the 5 marks*\n",
    "\n",
    "\n",
    "* Use the test set from Question 7 and provide the MSE obtained by having used minibatch training with the best values for $\\alpha$, $\\eta$ and $B$ over the WHOLE training data (not only the training set).\n",
    "\n",
    "* Compare the performance of the closed form solution and the minibatch solution. Are the performances similar? Are the parameters $\\mathbf{w}$ and $\\alpha$ similar in both approaches? Please comment on both questions.\n",
    "\n",
    "*2 marks of out of the 5 marks*\n",
    "\n",
    "#### Question 8 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-03 1.e-02 1.e-01 1.e+00 1.e+01]\n",
      "[0.01       0.01584893 0.02511886 0.03981072 0.06309573]\n",
      "[ 50 162 275 387 500]\n"
     ]
    }
   ],
   "source": [
    "num = 5\n",
    "\n",
    "a_q8 = np.logspace(-3, 1, num)\n",
    "eta_range = np.logspace(-2, -1.2, num)\n",
    "B_range = np.linspace(50, 500, num)\n",
    "B_range = B_range.astype(int) # make all the element in B_range become int type\n",
    "print(a_q8)\n",
    "print(eta_range)\n",
    "print(B_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain the data from training set\n",
    "y_train = pd.DataFrame(training_set.iloc[:,0])\n",
    "X_train = training_set.iloc[:,1:training_set.shape[1]]\n",
    "X_train = pd.DataFrame(np.hstack((np.ones(X_train.shape[0]).reshape(X_train.shape[0],1), X_train)))\n",
    "\n",
    "np.random.seed(MyStudentID)  # set random seed according to studentID\n",
    "w_train = np.random.randn(X_train.shape[1],1)   # randomly initialise a column vector w_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MBGD(X,y,w,a,eta,B): # define a minibatch gradient descent function for 500 iteration\n",
    "    w_new = np.zeros(X.shape[1]).reshape(X.shape[1],1)\n",
    "    for j in range(500):\n",
    "        for i in range(0,X.shape[0],B):  # for every B data,update gradient for once           \n",
    "            Xi = np.array(X.iloc[i:i+B]) \n",
    "            yi = np.array(y.iloc[i:i+B])\n",
    "            diff = -2/B * (Xi.T).dot(yi) + 2/B * ((Xi.T).dot(Xi)).dot(w) + a*w # compute the dJ/dw\n",
    "            w = w - eta * (1.0 / B)* diff #update the w \n",
    "            w_new = w\n",
    "    return w_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train_values = [] #run the minibatch gradient descent,store all the w values in order to compute all the possible MSE\n",
    "for a in a_q8: # use for loops to compute w, by using different combination of a,eta and B \n",
    "    for eta in eta_range:\n",
    "        for B in B_range:\n",
    "            w_temp = MBGD(X_train,y_train,w_train,a,eta,B)\n",
    "            w_train_values.append(w_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_train_values) # so now we have 5 x 5 x 5 = 125 w,through the index of w_train_values,we can know the exact a[],eta[],B[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array(y2).reshape(y2.shape[0],1) #adjust the dimension of y2 inorder to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_q8 = []\n",
    "for w in w_train_values:\n",
    "    MSE = ((y2 - X2.dot(w)).T.dot(y2 - X2.dot(w)))/ validation_set.shape[0] #MSE on validation data\n",
    "    MSE_q8.append(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25781885]]\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "temp = MSE_q8[0] # initialise a temp to compare\n",
    "index = 0 # index of the minimum MSE we want\n",
    "\n",
    "for i in range(len(MSE_q8)): # look through the all the MSE values to find minimum MSE and output the index\n",
    "    if MSE_q8[i]<temp:\n",
    "        temp = MSE_q8[i]\n",
    "        index = i \n",
    "print(temp)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#so the minimum MSE is MSE_q8[45] = 0.25781885 in this case,now compute the respoding index of a,eta,B\n",
    "index_a = int(45/(num*num))\n",
    "index_eta = (45/5)%num\n",
    "index_B = 45%num\n",
    "print(index_a)\n",
    "print(index_eta)\n",
    "print(index_B)\n",
    "#so in this case, when a_q8[1] , eta_range[4], B_range[0],we have the minimum MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the training data y and X in Question 5 ,use the best a,eta,B to compute w_td \n",
    "y_td = pd.DataFrame(y)\n",
    "X_td = pd.DataFrame(X)\n",
    "w_td = MBGD(X_td,y_td,w_train,a=a_q8[1],eta=eta_range[4],B=B_range[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22418088]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the w_td to compute MSE on the test set\n",
    "np.array(yt).reshape(yt.shape[0],1) \n",
    "MSE_td = ((yt - Xt.dot(w_td)).T.dot(yt - Xt.dot(w_td)))/ preprocessed_test_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22418088]]\n",
      "0.2210297368124787\n"
     ]
    }
   ],
   "source": [
    "print(MSE_td) #the MSE calculated in Q8,using minibatch gradient descent\n",
    "print(MSE_t) #the MSE calculated in Q7,using closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[[ 0.34069227]\n",
      " [ 0.10433369]\n",
      " [ 0.1102101 ]\n",
      " [ 0.12582252]\n",
      " [ 0.10815551]\n",
      " [-0.07930423]\n",
      " [ 0.08880714]\n",
      " [ 0.08040692]\n",
      " [ 0.10196405]\n",
      " [-0.00705569]\n",
      " [ 0.00438843]\n",
      " [-0.0034899 ]]\n",
      "0.01\n",
      "[[ 2.15171794]\n",
      " [ 0.29331335]\n",
      " [ 0.35063348]\n",
      " [ 0.31571867]\n",
      " [ 0.49817022]\n",
      " [ 0.09143795]\n",
      " [ 0.10332368]\n",
      " [ 0.33329443]\n",
      " [-0.17803292]\n",
      " [-0.22486161]\n",
      " [-0.12949103]\n",
      " [-0.00407673]]\n"
     ]
    }
   ],
   "source": [
    "#the a and w in Q7\n",
    "print(a_range[0])\n",
    "print(w)\n",
    "\n",
    "#the a and w in Q8\n",
    "print(a_q8[1])\n",
    "print(w_td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Batch Gradient Descent, parameters are updated after computing the gradient of error with respect to the entire training set. But in Mini-Batch Gradient Descent, parameters are updated after computing the gradient of error with respect to a subset of the training set. Mini-Batch Gradient Descent makes a compromise between the speedy convergence and the noise associated with gradient update which makes it a more flexible and robust algorithm.\n",
    "\n",
    "By printing out the results, the performances(MSE) are very similar, but parameters w and a are quite different here.These may also affcted by the initialised range of a,eta,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
